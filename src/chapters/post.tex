\chapter{Postulates of quantum mechanics}

TODO \todo{longer intro?}

Now that we defined Hilbert spaces and their operators in great detail, we can finally present we needed this mathematical foundations in order to progress: quantum mechanics is developed over Hilbert spaces with \tit{countable} bases, and quantum computing works with finite-dimensional Hilbert spaces. In particular, these are the four fundamental \tbf{postulates of quantum mechanics}.

\section{Postulates of quantum mechanics}

\subsection{First postulate}

\begin{framedpost}{State postulate}
	The state of a quantum system is completely described by a vector $\ket \psi$ in a Hilbert space $\mathcal H$.
\end{framedpost}

As we saw at the beginning of the previous chapter, $\ket \psi$ is always considered to be normalized. We observe that different physical systems of different types live in different Hilbert spaces.

\subsection{Second postulate}

\begin{framedpost}[label={time post}]{Time evolution postulate}
	A closed system evolves through time according to the \tbf{time-dependent Schrödinger equation (TDSE)}: $$i \hbar \dfrac{\diff}{\diff t} v(t) = Hv(t)$$
\end{framedpost}

We observe that the Schrödinger equation is a first-order linear differential equation, and it is composed by the following elements:

\begin{itemize}
	\item $v(t)$ which is the state vector at time $t$ (a vector in a Hilbert space)
	\item $H$ which is the system \tit{Hamiltonian}, a self-adjoint operator that describes the total energy of the system
\end{itemize}

The solution of the Schrödinger equation is $$v(t_1) = U(t_2, t_1)v(t_1)$$ where $U(t_2, t_1)$ is called \tbf{time-evaluation operator}, and it is defined as follows: $$U(t_2, t_1) = e^{-\tfrac{i}{\hbar}H(t_2 - t_1)}$$ (assuming $H$ does not depend on time). We recall that $H$ is a matrix, so we are raising $e$ to the power of a matrix, an operation that is defined by the power series of the exponential as follows: $$e^A = \sum_{n = 0}^\infty{\dfrac{A^n}{n!}}$$ What is interesting about this operator is that $U$ is \tbf{unitary}, and in order to show it is suffices to prove that $U^\dag = U^{-1}$. But how do we compute the adjoint of $U$? We observe that by the properties of the adjoint operation it holds that $$\rbk{e^A}^\dag = \rbk{\sum_{n = 0}^\infty{\dfrac{A^n}{n!}}}^\dag = \sum_{n = 0}^\infty{\dfrac{(A^n)^\dag}{n!}} = \sum_{n = 0}^\infty{\dfrac{(A^\dag)^n}{n!}} = e^{A^\dag}$$ which means that the adjoint of an exponential is the exponential of the adjoint --- to be precise, we implicitly used the fact that the adjoint operation is \tit{continuous}. This suffices to prove that $$U^\dag = \rbk{e^{-\tfrac{i}{\hbar}H(t_2 - t_1)}}^\dag = e^{\rbk{-\tfrac{i}{\hbar}H(t_2 - t_1)}^\dag} = e^{\tfrac{i}{\hbar}H(t_2 - t_1)} = \rbk{e^{-\tfrac{i}{\hbar}H(t_2 - t_1)}}^{-1} = U^{-1}$$

This is a crucial characteristic for quantum mechanics: since $U$ is unitary, we know that it preserves the scalar product by \cref{unitary alt def}, therefore it also preserves \tbf{probabilities and norms}. This is why we say that evolution in quantum systems --- or \tit{quantum evolution}, for short --- is unitary. Indeed, the second postulate is sometimes formulated equivalently as follows.

\begin{framedpost}{Time evolution postulate (alt. ver.)}
	The evolution of a \tit{closed} quantum system is described by a \tit{unitary transformation}. That is, the state $\ket \psi$ of the system at time $t_1$ is related to the state $\ket{\psi'}$ of the system at time $t_2$ as follows $$\ket{\psi'} = U \ket \psi$$ where $U(t_2, t_1) = e^{-\tfrac{i}{\hbar}H(t_2 - t_1)}$.
\end{framedpost}

\subsection{Third postulate}

\begin{framedpost}[label={meas post}]{Measurement postulate}
	Every measurable (i.e. \tit{observable}) quantity corresponds to a self-adjoint operator on $\mathcal H$. In particular, given an observable $A$, and a state $v \in \mathcal H$, it holds that:
	\begin{itemize}
		\item the only possible results of measuring $A$ are one of its eigenvalues
		\item the probability of measuring eigenvalue $\lambda$ in state $v$ is given by $$\Pr[A = \lambda \mid v] = \braket{v|P_\lambda v}$$ where $P_\lambda$ is the linear map that projects $v$ onto the $\lambda$-eigenspace.
	\end{itemize}
\end{framedpost}

We can actually explain why we choose that particular scalar product to be the probability. Since by convention any quantum state is normalize, i.e. $\norm v = 1$, it holds that
\begin{equation*}
	\begin{split}
		1 & = \norm{v}^2                                                                 \\
		  & = \braket{v|v}                                                               \\
		  & = \abk{\sum_{i = 1}^m{P_{\lambda_i}v}\middle|\sum_{j = 1}^m{P_{\lambda_j}v}} \\
		  & = \sum_{i = 1}^m{\sum_{j = 1}^m{\braket{P_{\lambda_i}v|P_{\lambda_j}v}}}     \\
	\end{split}
\end{equation*}
Now, since each $P_{\lambda_i}$ is a projector, we know that when $i \neq j$ it holds that $P_{\lambda_i}P_{\lambda_j} = \mathbf 0$, therefore by Hermiticity of projectors we have that

\begin{itemize}
	\item if $i \neq j$ then $$\braket{P_{\lambda_i}v|P_{\lambda_j}v} =\braket{v|P_{\lambda_i}P_{\lambda_j}v} = \braket{v| \mathbf 0 v} = 0$$
	\item if $i = j$ then $$\braket{P_{\lambda_i}v|P_{\lambda_j}v} = \braket{P_{\lambda_i}v|P_{\lambda_i}v} = \norm{P_{\lambda_i}v}^2$$
\end{itemize}

Therefore, by adding only the non-zero terms we get that $$\sum_{i = 1}^m{\norm{P_{\lambda_i}v}^2} = 1$$ Hence, we define $$\Pr[A = \lambda_i \mid v] := \norm{P_{\lambda_i}v}^2$$ such that $$\Pr[A \mid v] = \sum_{i = 1}^m{\Pr[A = \lambda_i \mid v]} = \sum_{i = 1}^m{\norm{P_{\lambda_i}v}^2} = \norm{v}^2 = 1$$ which also means that our probabilities will add up to 1 automatically. Finally, we can rewrite this proability as follows (we will drop the index of the eigenvalue):
\begin{equation*}
	\begin{alignedat}{2}
		\Pr[A = \lambda \mid v] & = \braket{P_\lambda v | P_\lambda v}      &                               \\
		                        & = \braket{v | P_\lambda^\dag P_\lambda v} &                               \\
		                        & = \braket{v | P_\lambda^2 v}              & \quad (\mbox{by Hermiticity}) \\
		                        & = \braket{v | P_\lambda P_\lambda v}      &                               \\
		                        & = \braket{v | P_\lambda v}                &                               \\
	\end{alignedat}
\end{equation*}

This formulation was refined in 1926 by Max Born \cite{born}, when he derived the following property.

\begin{framedthm}[label={born rule}]{Born rule}
	The probability that a qubit $\ket \psi$ written in a basis $\{\lambda_i\}_{i = 1}^n$ collapses to a particular $\ket \lambda \in \{\lambda_i\}_{i = 1}^n$ when measured is $$\Pr[\mbox{measure}(\ket \psi) = \ket \lambda] = \abs{\braket{\psi|\lambda}}^2$$
\end{framedthm}

\begin{proof}
	By the \cref{spectral thm 2} it holds that the set of all the eigenvectors $\ket \lambda$ of any operator can be expanded to always form an orthonormal basis of the complete Hilbert space. Hence, the idea is to implicitly construct a self-adjoint operator $A$ whose eigenvalues are precisely the possible values in which $\ket \psi$ might collapse into. In other words, we want to construct a self-adjoint operator whose \nameref{spectral decomp} is exactly defined by $\{\lambda_1, \ldots, \lambda_n\}$ Hence, if $\ket \psi$ is defined as $$\ket \psi = \sum_{i = 1}^n {\alpha_n \ket{\lambda_i}}$$ we define the operator $$A_{\psi} = \sum_{i = 1}^n{\lambda_i \ket{\lambda_i} \bra{\lambda_i}}$$ Thus, the probability that by $\ket \psi$ it collapses to some $\ket \lambda \in\{\lambda_1, \ldots, \lambda_n\}$ can be rewritten as follows:
	\begin{equation*}
		\begin{alignedat}{2}
			\Pr[\mbox{measure}(\ket \psi = \ket \lambda)] & = \Pr[A_\psi = \lambda | \ket \psi]            &                                    \\
			                                              & = \braket{\psi|P_\lambda \psi}                 & \quad (\mbox{by the \nameref{meas post}}) \\
			                                              & = \braket{\psi|\lambda} \braket{\lambda| \psi}
			                                              & = \abs{\braket{\psi|\lambda}}^2                &                                    \\
		\end{alignedat}
	\end{equation*}
\end{proof}

For instance, if we have a superposition $$\ket \psi = \alpha \ket 0 + \beta \ket 1$$ and we want to know what is the probability that $\ket \psi$ collapses to $\ket 0$ after a measurement, we simply have that
\begin{equation*}
	\begin{split}
		\Pr[\mbox{measure}(\ket \psi = \ket 0)] & = \Pr[A_\psi = 0 | \ket \psi] \\
		                                        & = \abs{\braket{\psi|0}}^2     \\
	\end{split}
\end{equation*}
where the $A_\psi$ matrix is precisely: $$A_\psi = 0 \cdot P_0 + 1 \cdot P_1 = 0 \cdot \ket 0 \bra 0 + 1 \cdot \ket 1 \bra 1$$ This formulation of the probability of measurements will be used extensively for our purposes, and allows us to avoid the description of the matrix $A_\psi$ completely.

Before presenting to the next postulate, another very important operator that is frequently utilized in quantum mechanics is the \tbf{expected value} of a matrix. Given an observable $A$, we define the expected value of $A$ as the average eigenvector we may obtain after a measurement $$\Exp[A | v] = \sum_{i = 1}^m{\lambda_i \Pr[A = \lambda_i \mid v]}$$ We usually denote the expected value of the operator $A$ given that we are in state $\ket \psi$ as $\abk A_\psi$ (or $\abk A$ if the context is clear enough). Moreover, we have the following property.

\begin{framedprop}[label={exp of an op}]{Expected value of an operator}
	Given an Hermitian operator $A$, if the system is in state $\ket \psi$ it holds that $$\abk{A}_\psi = \braket{\psi|A \psi}$$
\end{framedprop}

\begin{proof}
	By the \nameref{meas post}, it follows that
	\begin{equation*}
		\begin{alignedat}{2}
			\abk{A}_\psi & = \Exp[A \mid \ket \psi]                                                    &                                                              \\
			             & = \sum_{i = 1}^m \lambda_i \Pr[A = \lambda_i \mid \ket \psi]                                                                               \\
			             & = \sum_{i = 1}^m \lambda_i \braket{\psi|P_{\lambda_i}|\psi}                 &                                                              \\
			             & = \bra \psi \left( \sum_{i = 1}^m \lambda_i P_{\lambda_i} \right) \ket \psi &                                                              \\
			             & = \bra \psi A \ket \psi                                                     & \quad \quad (\mbox{this is $A$'s \nameref{spectral decomp}}) \\
			             & = \braket{\psi| A \psi}                                                     &                                                              \\
		\end{alignedat}
	\end{equation*}
\end{proof}

Notably, \cref{trace prop} directly implies the following observation.

\begin{framedcor}{}
	Given an Hermitian operator $A$, if the system is in state $\ket \psi$ it holds that $$\abk{A}_\psi = \tr(A \ket \psi \bra \psi)$$
\end{framedcor}

\subsection{Fourth postulate}

\begin{framedpost}{Composite systems postulate}
	If system $A$ is defined over $\mathcal H_A$, and system $B$ is defined over $\mathcal H_B$, the total system lives in $$\mathcal H_{AB} = \mathcal H_A \otimes \mathcal H_B$$
\end{framedpost}

In other words, the last postulate states that the Hilbert space of a composite system is the tensor product of the Hilbert spaces of its subsystems. This postulate immediately tells us something important about \tbf{entangled} quantum systems: if a system $C$ defined over a Hilbert space $\mathcal H_C$ represents a quantum state, there is no pair of systems $A$ and $B$ defined over $\mathcal H_A$ and $\mathcal H_B$ such that $\mathcal H_C = \mathcal H_A \otimes \mathcal H_B$.

Speaking of tensor products, when operators can be factored out into smaller operators of smaller systems we obtain linearity of expectations w.r.t. the tensor product.

\begin{framedprop}{}
	Given an operator $O$ that can be factored out as $O = A \otimes B$, if the current state $\ket \psi$ is not entangled it holds that $$\abk{O} = \abk{A} \cdot \abk{B}$$
\end{framedprop}

% \begin{proof}
% 	We need to show that $$\braket{\psi|O\psi} = \braket{\psi_A| A\psi_A} \cdot \braket{\psi_B|B\psi_B}$$ where $\ket \psi = \ket{\psi_A} \otimes \ket{\psi_B}$ which we know they exist because we are assuming that $\ket \psi$ is not entangled. Let the following be the spectral decompositions of $A$ and $B$, respectively $$A = \sum_{i = 1}^m{\lambda_i^A \ket{\lambda_i^A} \bra{\lambda_i^A}} \quad \quad B = \sum_{j = 1}^m{\lambda_j^B \ket{\lambda_j^B} \bra{\lambda_j^B}}$$ Then, by computing the tensor product between $A$ and $B$ we immediately obtain the spectral decomposition of $O$: $$O = A \otimes B = \sum_{i, j \in [m]}{\lambda_i^A\lambda_j^B (\ket{\lambda_i^A} \otimes \ket{\lambda_j^B})(\bra{\lambda_i^A} \otimes \bra{\lambda_j^B})}$$ Hence, the possible values $O$ might be observed into are all the products $\lambda_i^A \lambda_j^B$ for $i, j \in [m]$. Lastly, if we define $$\forall i, j \in [m] \quad \lambda_k = \lambda_{(i - 1)m + j}$$ it suffices to consider the definition of expected value:
%
% 	\begin{equation*}
% 		\begin{split}
% 			\braket{\psi|O\psi} & = \sum_{k = 1}^{m^2}{\lambda_k \Pr[O = \lambda_k \mid \ket \psi]}                                                                                            \\
% 			                    & = \sum_{k = 1}^{m^2}{\lambda_k \Pr[A \otimes B = \lambda_k \mid \ket {\psi_A} \otimes \ket{\psi_B}]}                                                         \\
% 			                    & = \sum_{k = 1}^{m^2}{\lambda_k \abs{\braket{\psi_A \otimes\psi_B | \lambda_k}}^2}                                                                            \\
% 			                    & = \sum_{i = 1}^m{\sum_{j = 1}^m{\lambda_i^A \lambda_j^B \abs{\braket{\psi_A \otimes \psi_B|\lambda_i^A \otimes \lambda_j^B}}^2}}                             \\
% 			                    & = \sum_{i = 1}^m{\sum_{j = 1}^m{\lambda_i^A \lambda_j^B \abs{\braket{\psi_A|\lambda_i^A} \cdot \braket{\psi_B|\lambda_j^B}}^2}}                              \\
% 			                    & = \sum_{i = 1}^m{\sum_{j = 1}^m{\lambda_i^A \lambda_j^B \abs{\braket{\psi_A|\lambda_i^A}}^2 \cdot \abs{\braket{\psi_B|\lambda_j^B}}^2}}                      \\
% 			                    & = \rbk{\sum_{i = 1}^m{\lambda_i^A \abs{\braket{\psi_A|\lambda_i^A}}^2}} \cdot \rbk{\sum_{j = 1}^m{\lambda_j^B \abs{\braket{\psi_B|\lambda_j^B}}^2}}          \\
% 			                    & = \rbk{\sum_{i = 1}^m{\lambda_i^A \Pr\sbk{A = \lambda_i^A| \ket{\psi_A}}}} \cdot \rbk{\sum_{j = 1}^m{\lambda_j^B  \Pr\sbk{B = \lambda_j^B | \ket {\psi_B}}}} \\
% 			                    & = \braket{\psi_A| A \psi_A} \cdot \braket{\psi_B|B \psi_B}                                                                                                   \\
% 		\end{split}
% 	\end{equation*}
% \end{proof}

\begin{proof}
	We need to show that
	\[
		\braket{\psi|O\psi} = \braket{\psi_A| A\psi_A} \cdot \braket{\psi_B|B\psi_B}
	\]
	where $\ket \psi = \ket{\psi_A} \otimes \ket{\psi_B}$, which we know exists because we are assuming that $\ket \psi$ is not entangled.

	Let the following be the spectral decompositions of $A$ and $B$, respectively:
	\[
		A = \sum_{i = 1}^m{\lambda_i^A P_{\lambda_i^A}}, \quad\quad B = \sum_{j = 1}^m{\lambda_j^B P_{\lambda_j^B}}
	\]
	Then, by computing the tensor product between $A$ and $B$, we immediately obtain the spectral decomposition of $O$:
	\[
		O = A \otimes B = \sum_{i, j \in [m]}{\lambda_i^A\lambda_j^B (P_{\lambda_i^A} \otimes P_{\lambda_j^B})}
	\]
	Hence, the possible values $O$ might be observed into are all the products $\lambda_i^A \lambda_j^B$ for $i, j \in [m]$. Lastly, if we define
	\[
		\forall i, j \in [m] \quad \lambda_k = \lambda_{(i - 1)m + j}
	\]
	it suffices to consider the definition of expected value:

	\begin{equation*}
		\begin{split}
			\braket{\psi|O\psi}
			 & = \sum_{k = 1}^{m^2} \lambda_k \Pr[O = \lambda_k \mid \ket \psi]                                                                                                                  \\
			 & = \sum_{i = 1}^m \sum_{j = 1}^m \lambda_i^A \lambda_j^B \Pr[A \otimes B = \lambda_i^A \lambda_j^B \mid \ket{\psi_A} \otimes \ket{\psi_B}]                                         \\
			 & = \sum_{i = 1}^m \sum_{j = 1}^m \lambda_i^A \lambda_j^B \braket{\psi_A \otimes \psi_B | P_{\lambda_i^A} \otimes P_{\lambda_j^B} | \psi_A \otimes \psi_B}                          \\
			 & = \sum_{i = 1}^m \sum_{j = 1}^m \lambda_i^A \lambda_j^B \left( \braket{\psi_A | P_{\lambda_i^A} | \psi_A} \cdot \braket{\psi_B | P_{\lambda_j^B} | \psi_B} \right)                \\
			 & = \sum_{i = 1}^m \left( \lambda_i^A \braket{\psi_A | P_{\lambda_i^A} | \psi_A} \sum_{j = 1}^m \lambda_j^B \braket{\psi_B | P_{\lambda_j^B} | \psi_B} \right)                      \\
			 & = \left( \sum_{i = 1}^m \lambda_i^A \braket{\psi_A | P_{\lambda_i^A} | \psi_A} \right) \cdot \left( \sum_{j = 1}^m \lambda_j^B \braket{\psi_B | P_{\lambda_j^B} | \psi_B} \right) \\
			 & = \braket{\psi_A| A \psi_A} \cdot \braket{\psi_B| B \psi_B}
		\end{split}
	\end{equation*}
\end{proof}

This result should not come as a surprise, since for any two distributions $X$ and $Y$ we know that $$\Exp[XY] = \Exp[X] \cdot \Exp[Y]$$ only if $X$ and $Y$ are \tbf{independent}. Indeed, by assuming that $O$ and $\ket \psi$ can be factorized, we are assuming that the two underlying subsystems $\mathcal H_A$ and $\mathcal H_B$ --- in which $\ket{\psi_A}$ and $A$,  and $\ket{\psi_B}$ and $B$ live, respectively --- are \curlyquotes{independent} in the sense that they are \tit{not entangled}!

\section{The density operator}

We have formulated quantum mechanics using state vectors and the four postulates described in the previous section. However an alternate formulation is possible using a tool known as the \tbf{density operator}, or \tit{density matrix}. This formulation will be mathematically equivalent to the state vector approach. However, before proceeding we need to revise some definitions we provided in the previous section.

\subsection{Generalization of the third postulate}

The postulates we have just presented are internally consistent, however, to proceed further we require additional clarification regarding the \nameref{meas post}. In particular, in the statement of this postulate we required that measurables are self-adjoint (i.e. Hermitian) operators. To be precise, this is a special case of a more general formalization of the Measurement postulate which we need to discuss.

\begin{framedpost}[label={gen meas post}]{General measurement postulate}
	Quantum measurements are described by a collection $M = \{M_m\}$ of \tit{measurement operators} acting on the state space of the system being measured --- the index $m$ refers to the measurement outcomes that may occur in the experiment. If the state of the quantum system is $\ket \psi$ immediately before the measurement, then the probability that result $m$ occurs is given by $$\Pr[M = m \mid \ket \psi] = \bra \psi M_m^\dag M_m \ket \psi$$ and the measurement operators satisfy the \tbf{completeness equation} $$\sum_{m}{M_m^\dag M_m} = I$$
\end{framedpost}

We observe that the completeness equation expresses the fact that probabilities of the outcomes sum to one:
\begin{equation*}
	\begin{split}
		\sum_{m}{\Pr[M = m \mid \ket \psi]} & = \sum_{m} {\bra \psi M_m^\dag M_m \ket \psi}     \\
		% & = \abk{\psi \middle| \sum_{m}{M_m^\dag M_m} \middle| \psi} \\
		                                    & = \bra \psi \rbk{\sum_m {M_m^\dag M_m}} \ket \psi \\
		                                    & = \braket{\psi|I|\psi}                            \\
		                                    & = \braket{\psi|\psi}                              \\
		                                    & = 1
	\end{split}
\end{equation*}

For instance, consider a single qubit $$\ket \psi = \alpha \ket 0 + \beta \ket 1$$ and suppose we want to measure it in the computational basis. The two measurement operators we require are precisely $$M_0 := \ket 0 \bra 0 \quad \quad M_1 := \ket 1 \bra 1$$ We observe that these two operators are \tit{projectors}, so they trivially satisfy the completeness equation
\begin{equation*}
	\begin{alignedat}{2}
		M_0^\dag M_0 + M_1^\dag M_1 & = M_0^2 + M_1^2 &                                        \\
		                            & = M_0 + M_1     & \quad \quad (\mbox{resolution of $I$}) \\
		                            & = I             &                                        \\
	\end{alignedat}
\end{equation*}
Then, the probability of obtaining 0 from measuring $\ket \psi$ is $$\Pr[M = 0 \mid \ket \psi] = \braket{\psi|M_0^\dag M_0|\psi} = \braket{\psi|M_0|\psi} = \abs{\alpha}^2$$ and similarly we ge that $\Pr[M = 1 \mid \ket \psi] = \abs{\beta}^2$, as we would expect.

So, what is the connection with the initial version of the third postulate we originally provided? A special case of the General measurement postulate when the measurements are \tit{projective measurements}, i.e. measurements described by Hermitian operators. Indeed, for many applications of quantum computation and quantum information in general we are concerned primarily with projective measurements. By requiring that observables are Hermitian operators the third postulate reduces to the formulation we provided in the previous section, because any observable $M$ would have a spectral decomposition of $$M = \sum_{m}{m P_m}$$ We will discuss this fact in greater detail in the next section.

\subsection{Postulates through density operators}

We can now introduce the \tbf{density operator} discussed at the beginning of the section. First, we describe the context. Consider a quantum system, and suppose that it is in one of a number of states $\ket{\psi_1}, \ldots, \ket{\psi_N}$. Each $\ket{\psi_i}$ is associated with a probability $p_i$ that the system is in the $i$-th state. We call $$\{p_i, \ket {\psi_i}\}_{i = 1}^N$$ an \tbf{ensamble of states}. Then, we the following definition.

\begin{frameddefn}{Density operator}
	Given a quantum system described by the ensamble $\{p_i, \ket{\psi_i}\}_{i = 1}^N$, the \tbf{density operator} of the system is defined as follows $$\rho := \sum_{i = 1}^N{p_i \ket{\psi_i} \bra{\psi_i}}$$
\end{frameddefn}

We observe that $\rho$ is a matrix, and this is the reason why it is interchangeably called \tit{density matrix}. Nevertheless, this matrix is important because it turns out that all the postulates of quantum mechanics we presented so far can be reformulated equivalently in terms of the density operator.

Suppose that we have closed quantum system described by some ensamble $\{p_i, \ket{\psi_i}\}_{i = 1}^N$ that unitarily evolves following the unitary operator $U$ described earlier $$U(t_2, t_1) = e^{-\tfrac{i}{\hbar}H(t_2 - t_1)}$$ This means that the system is in state $\ket{\psi_i}$ with probability $p_i$, and after the evolution has occurred the system will be in the state $U \ket{\psi_i}$ still with probability $p_i$. More specifically, we have that $$\ket{\psi_i} \xlongrightarrow{U} U \ket{\psi_i}$$ which also directly implies that $$(\ket{\psi_i})^\dag = \bra{\psi_i} \xlongrightarrow{U} (U \ket{\psi_i})^\dag = \bra{\psi_i} U^\dag$$ Therefore, after the system has evolved we must \tit{update} its density operator by applying $U$ to each $\ket{\psi_i}$ $$\rho = \sum_{i = 1}^N{p_i \ket{\psi_i} \bra{\psi_i}} \xlongrightarrow{U} \sum_{i = 1}^N{p_i U \ket{\psi_i} \bra{\psi_i} U^\dag} = U \rho U^\dag$$ Not surprisingly, this shows that by linearity we just need to apply $U$ (and $U^\dag$) to the matrix directly in order to consider all the evolutions. The function that maps $$\rho \mapsto U \rho U^\dag$$ is called \tbf{superoperator}.

Measurements can be also easily described through the density operator. Consider the \nameref{gen meas post}, and suppose we perform a measurement described by measurement operators $M_m$. If the initial state was $\ket{\psi_i}$, then we have that
\begin{equation*}
	\begin{alignedat}{2}
		\Pr[M = m|\ket{\psi_i}] & = \braket{\psi_i|M_m^\dag M_m|\psi_i}         &                                           \\
		                        & = \tr(M_m^\dag M_m \ket{\psi_i} \bra{\psi_i}) & \quad \quad (\mbox{by \cref{trace prop}}) \\
	\end{alignedat}
\end{equation*}
Then, thanks to \cref{trace tricks}, by computing the total probability we obtain that
\begin{equation*}
	\begin{split}
		\Pr[M = m] & = \sum_{i = 1}^N{p_i\Pr[M = m\mid \ket{\psi_i}]}                       \\
		           & = \sum_{i = 1}^N{p_i \tr(M_m^\dag M_m \ket{\psi_i} \bra{\psi_i})}      \\
		           & = \sum_{i = 1}^N{\tr(p_i M_m^\dag M_m \ket{\psi_i} \bra{\psi_i})}      \\
		           & = \tr \rbk{\sum_{i = 1}^N{p_i M_m^\dag M_m \ket{\psi_i} \bra{\psi_i}}} \\
		           & = \tr \rbk{M_m^\dag M_m \sum_{i = 1}^N{p_i \ket{\psi_i} \bra{\psi_i}}} \\
		           & = \tr(M_m^\dag M_m \rho)                                               \\
	\end{split}
\end{equation*}

This shows that the basic postulates of quantum mechanics related to unitary evolution and measurement can be rephrased in terms of density operators. However, we can do better: we will proivde a characterization of the density operator that does not rely on the idea of state vectors \tit{at all}. But first, as usual, we need some definitions. When a quantum system is an a known exact state $\ket \psi$, the system is said to be in a \tbf{pure state}, and in this case its density matrix operator is simply $$\rho = \ket \psi \bra \psi$$ Otherwise, if the state is now known and the system is described by an ensamble of states, we say that $\rho$ is in a \tbf{mixed state}. More specifically, we can distinguish between pure and mixed states as follows.

\begin{framedprop}[label={mixed prop}]{}
	If a system is in a pure state it holds that $\tr(\rho^2) = 1$, otherwise if it is in a mixed state it holds that $\tr(\rho^2) < 1$.
\end{framedprop}

\begin{proof}
	Consider a density matrix describing a pure state $\rho = \ket \psi \bra \psi$; by the properties of the trace it holds thta
	\begin{equation*}
		\begin{split}
			\tr(\rho^2) & = \tr (\rho \ket \psi \bra \psi)        \\
			            & = \braket{\psi|\rho \psi}               \\
			            & = \braket{\psi|\psi} \braket{\psi|\psi} \\
			            & = \abs{\braket{\psi|\psi}}^2            \\
			            & = 1                                     \\
		\end{split}
	\end{equation*}
	Differently, consider a density matrix $$\rho = \sum_{i = 1}^N{p_i \ket {\psi_i} \bra{\psi_i}}$$ describing a mixed state of some ensamble $\{p_i, \ket{\psi_i}\}_{i = 1}^N$. Then, through algebraic manipulation we obtain that
	\begin{equation*}
		\begin{alignedat}{2}
			\tr(\rho^2) & = \tr \rbk{\rbk{\sum_{i = 1}^N p_i\ket{\psi_i} \bra{\psi_i}} \rbk{\sum_{j = 1}^N p_j\ket{\psi_j} \bra{\psi_j}}} &                                             \\
			            & = \tr \rbk{\sum_{i = 1}^N  \sum_{j = 1}^N p_i p_j \ket{\psi_i} \braket{\psi_i|\psi_j} \bra{\psi_j}}             &                                             \\
			            & = \sum_{i = 1}^N \sum_{j = 1}^N p_i p_j \braket{\psi_i|\psi_j}\tr(\ket{\psi_i} \bra{\psi_j})                    &                                             \\
			            & = \sum_{i = 1}^N \sum_{j = 1}^N p_i p_j \braket{\psi_i|\psi_j} \braket{\psi_j|\psi_i}                           & \quad \quad (\mbox{by \cref{broken trace}}) \\
			            & = \sum_{i = 1}^N \sum_{j = 1}^N p_i p_j \braket{\psi_i|\psi_j} \overline{\braket{\psi_i|\psi_j}}                &                                             \\
			            & = \sum_{i = 1}^N \sum_{j = 1}^N p_i p_j \abs{\braket{\psi_i|\psi_j} }^2                                         &                                             \\
		\end{alignedat}
	\end{equation*}
	Without loss of generality, we observe that we can assume all the $\ket{\psi_i}$'s in the ensamble that $\rho$ describes are distinct --- up to changing the probabilities accordingly. Then, this means that for any $i, j \in [N]$ $$\abs{\braket{\psi_i|\psi_j}}^2 = 1\iff \ket{\psi_i} = e^{i \theta} \ket{\psi_j}$$ for some phase $\theta$. In other words, the norm of the projection of $\psi_j$ onto $\psi_i$ is equal to 1 if and only if $\ket{\psi_i}$ and $\ket{\psi_j}$ are the same state up to a global phase. However, since qubits cannot be distinguished up to a global phase, we can assume that the ensamble $\rho$ describes does not contain such pair of states. This implies that
	\begin{equation*}
		\begin{split}
			 & i = j \implies \abs{\braket{\psi_i|\psi_j}}^2  = 1   \\
			 & i \neq j \implies \abs{\braket{\psi_i|\psi_j}}^2 < 1 \\
		\end{split}
	\end{equation*}
	Moreover, since the state is mixed, we can also assume without loss of generality that for all $i \in [N]$ it holds that $p_i \neq 0, 1$. From these observations, we conclude that
	\begin{equation*}
		\begin{alignedat}{2}
			\tr(\rho^2) & = \sum_{i = 1}^N \sum_{j = 1}^N p_i p_j \abs{\braket{\psi_i|\psi_j} }^2 & \\
			            & < \sum_{i = 1}^N \sum_{j = 1}^N p_i p_j                                 & \\
			            & = \rbk{\sum_{i = 1}^N p_i} \rbk{\sum_{i = 1}^N p_j}                     & \\
			            & = \rbk{\sum_{i = 1}^N p_i}^2                                              \\
			            & = 1
		\end{alignedat}
	\end{equation*}
\end{proof}

We can finally present the characterization of density operators we anticipated.

\begin{framedthm}[label={density op thm}]{Density operators characterization}
	An operator $\rho$ is the density operator of some system described by an ensamble $\{p_i, \ket{\psi_i}\}_{i = 1}^N$ if and only if

	\begin{itemize}
		\item $\rho$ is positive
		\item $\tr(\rho) = 1$
	\end{itemize}
\end{framedthm}

\begin{proof}
	We first prove the first implication. Consider the density operator $$\rho = \sum_{i = 1}^N{p_i \ket{\psi_i} \bra{\psi_i}}$$ Fix an arbitrary $\ket v \in \mathcal H$; then, we get that:
	\begin{equation*}
		\begin{split}
			\braket{v|\rho v} & = \braket{v|\rho|v}                                                 \\
			                  & = \bra v \rbk{\sum_{i = 1}^N{p_i \ket{\psi_i} \bra{\psi_i}}} \ket v \\
			                  & = \sum_{i = 1}^N{p_i \braket{v|\psi_i} \braket{\psi_i| v}}          \\
			                  & = \sum_{i = 1}^N{p_i \abs{\braket{v|\psi_i}}^2}                     \\
			                  & \ge 0
		\end{split}
	\end{equation*}
	This proves that $\rho$ is positive. For the second statement, by the properties of the trace proved in \cref{trace tricks} and \cref{trace prop}, we obtain that
	\begin{equation*}
		\begin{split}
			\tr(\rho) & = \tr \rbk{\sum_{i = 1}^N{p_i \ket{\psi_i} \bra{\psi_i}}} \\
			          & = \sum_{i = 1}^N{p_i \tr(\ket{\psi_i} \bra{\psi_i})}      \\
			          & = \sum_{i = 1}^N{p_i \braket{\psi_i|\psi_i}}              \\
			          & = \sum_{i = 1}^n{p_i}                                     \\
			          & = 1
		\end{split}
	\end{equation*}

	Now we can proceed to prove the converse implication. Suppose that $\rho$ is any operator that satisfies the conditions of the statement. In particular, since $\rho$ is positive by \cref{positive prop} we know that $\rho$ is Hermitian, which implies that it admits a spectral decomposition $$\rho = \sum_{j}{\lambda_j \ket{\lambda_j} \bra{\lambda_j}}$$ We can write its spectral decomposition in this fashion by repeating the degenerate eigenvalues multiple times as discussed under \cref{spectral decomp}. Let $P$ and $D$ such that $\rho$ is diagonalizable, i.e. $$\rho = PDP^{-1}$$ and in particular $D$ has the eigenvalues of $\rho$ on its diagonal. Then, we can use the assumption that $\tr(\rho) = 1$ to conclude that
	\begin{equation*}
		\begin{split}
			1 & = \tr(\rho)           \\
			  & = \tr(PDP^{-1})       \\
			  & = \tr(P^{-1} PD)      \\
			  & = \tr(D)              \\
			  & = \sum_{j}{\lambda_j} \\
		\end{split}
	\end{equation*}
	which means that the sum of the eigenvalues of $\rho$ adds up to 1. Finally, by positivity of $\rho$ we know that $\lambda_j \ge 0$ for each $\lambda_j$, which means that the eigenvalues behave exactly as probabilities. This proves that $\rho$ is the density matrix of the system described by the ensamble $$\{\lambda_j, \ket{\lambda_j} \bra{\lambda_j}\}_j$$
\end{proof}

\begin{framedprop}{Convexity of density matrices}
	Given density matrices $\rho_1, \ldots, \rho_n$ and probabilities $p_1, \ldots, p_n$ it holds that $\sum_{i = 1}^N{p_i \rho_i}$ is a density matrix.
\end{framedprop}

\begin{proof}
	The proof follows immediately from the previous theorem. In fact, since each $\rho_i$ is a density matrix, by the previous theorem they must be positive, therefore for any $\ket v \in \mathcal H$ it holds that $$\bra v \rbk{\sum_{i = 1}^N{p_i \rho_i}} \ket v = \sum_{i = 1}^N{p_i\braket{v|\rho_iv}} \ge 0$$ Moreover, the previous theorem also states that $\tr(\rho_i) =1$ for each density matrix, which shows that $$\tr \rbk{\sum_{i = 1}^N{p_i \rho_i}} = \sum_{i = 1}^n{p_i \tr(\rho_i)} = \sum_{i=1}^N{p_i} = 1$$ Therefore, since the weighted sum is positive and its trace is equal to 1, the previous theorem implies that it is also a density matrix.
\end{proof}

Given all we just discussed, we can finally rephrase the postulates through the density operator.

\begin{framedpost}{State postulate (density operator)}
	Associated to any isolated physical system is a Hilbert space known as the \tit{state space} of the system, and the system is completely described by its \tit{density operator}, i.e. any positive operator $\rho$ with trace one acting on the state space of the system.
\end{framedpost}

\begin{framedpost}{Time evolution postulate (density op.)}
	The evolution of a \tit{closed} quantum system is described by a \tit{unitary transformation}, i.e. the state $\rho$ of the system at time $t_1$ is related to the state $\rho'$ of the system at time $t_2$ as follows $$\rho' = U \rho U^\dag$$ where $U(t_2, t_1) = e^{-\tfrac{i}{\hbar}H(t_2 - t_1)}$.
\end{framedpost}

\begin{framedpost}[label={gen meas post dens}]{General measurement postulate (dens. op.)}
	Quantum measurements are described by a collection $M =\{M_m\}$ of \tit{measurement operators} acting on the state space of the system being measured --- the index $m$ refers to the measurement outcomes that may occur in the experiment. If the state of the quantum system is $\rho$ immediately before the measurement, then the probability that result $m$ occurs is given by $$\Pr[M = m \mid \rho] = \tr(M_m^\dag M_m \rho)$$ and the measurement operators satisfy the \tbf{completeness equation} $$\sum_{m}{M_m^\dag M_m} = I$$
\end{framedpost}

\begin{framedpost}{Composite system postulate (dens. op.)}
	The sate space of a composite physical system is the tensor product of the state spaces of the component physical systems. That is, given $n$ systems such that the $i$-th system is in state $\rho_i$, the joint state of the total system is $$\rho = \bigotimes_{i = 1}^n{\rho_i}$$
\end{framedpost}

As a final note, observe that knowing the density matrix of a system tells us \tit{nothing} about the ensamble of states of the systems, because different ensambles can generate the same density matrix. For instance, the matrix $$\rho = \dfrac{1}{2} \rmat{1 & 0 \\ 0 & 1}$$ which can be generated as follows $$\rho = \dfrac{1}{2} \ket 0 \bra 0 + \dfrac{1}{2} \ket 1 \bra 1$$ This \tit{might} suggest that the ensamble of states of our system is $$\cbk{\rbk{\dfrac{1}{2}, \ket 0 \bra 0}, \rbk{\dfrac{1}{2}, \ket 1 \bra 1}}$$ but it would be a mistake to make this conclusion because $\rho$ can be also written for examòle as follows $$\rho = \dfrac{1}{4} \rmat{1 & 1 \\ 1 & 1} + \dfrac{1}{4} \rmat{1 & -1 \\ -1 & 1}$$ which describes a completely different ensamble!

\subsection{Entangled systems}

So far we only dealt with one single system, and its associated density operator, but perhaps the deepst application of the latter is as a descriptive tool for \tit{composite} quantum systems. Suppose we have two physical systems $A$ and $B$, whose composite state is described by a density operator $\rho^{AB}$. What can we say about $\rho^A$ and $\rho^B$?

\begin{frameddefn}{Partial trace}
	Given two quantum systems $A$ and $B$ defined over Hilbert spaces $\mathcal H_A$ and $\mathcal H_B$ respectively, we define the \tbf{partial trace} of $B$ as follows: $$\tr_B(\ket {a_1} \bra{a_2} \otimes \ket{b_1} \bra{b_2}) := \ket{a_1} \bra{a_2} \tr(\ket{b_1} \bra{b_2})$$
	for any $\ket{a_1}, \ket{a_2} \in \mathcal H_A$ and $\ket{b_1}, \ket{b_2} \in \mathcal H_B$.
\end{frameddefn}

The partial trace of $A$ is defined analogously. We observe that, by \cref{trace prop} if follows that $$\tr(\ket{b_1} \bra{b_2}) = \braket{b_2|b_1}$$ which means that $$\tr_B(\ket {a_1} \bra{a_2} \otimes \ket{b_1} \bra{b_2}) := \ket{a_1} \bra{a_2} \braket{b_2|b_1}$$ From this operator --- which can be proved to be \tbf{linear} --- we define the \tbf{reduced density operator}.

\begin{frameddefn}{Reduced density operator}
	Given two quantum systems $A$ and $B$ whose composite system is described by $\rho^{AB}$, we define the \tbf{reduced density operator} of $A$ as follows $$\rho^A := \tr_B(\rho^{AB})$$
\end{frameddefn}

The reduced density operator of $B$ is defined analogously.

Firstly, it is not obvious that $\rho^A$ is in any sense a description for the state of system $A$, so we shall discuss the definition. For instance, suppose that the composite quantum system of $A$ and $B$ is described by $\rho^{AB}$ that can itself be written as follows: $$\rho^{AB} = \tau \otimes \sigma$$ where $\tau$ is a density operator for $A$, and $\sigma$ is a density operator for $B$. First, suppose that $\tau$ and $\sigma$ represent pure states; then, the connection with the reduced density operator is evident by computing $\rho^A$
\begin{equation*}
	\begin{alignedat}{2}
		\rho^A & = \tr_B(\rho)                &                                                         \\
		       & = \tr_B(\tau \otimes \sigma) &                                                         \\
		       & = \tau \tr(\sigma)           & \quad \quad (\mbox{since they represent pure states})   \\
		       & = \tau                       & \quad \quad (\mbox{by \cref{density op thm}})         & \\
	\end{alignedat}
\end{equation*}
Similarly, we get that $\rho^B = \sigma$. For the general case, if we assume that $$\tau = \sum_{i = 1}^N p_i \ket{\phi_i} \bra{\phi_i} \quad \quad \sigma = \sum_{i =1}^N q_i \ket{\psi_i}\bra {\psi_i}$$ then we get that
\begin{equation*}
	\begin{split}
		\rho^A & = \tr_B(\rho)                                                                                                               \\
		       & = \tr_B(\tau \otimes \sigma)                                                                                                \\
		       & = \tr_B \rbk{\rbk{\sum_{i = 1}^N p_i \ket{\phi_i} \bra{\phi_i}} \otimes \rbk{\sum_{j = 1}^N q_j \ket{\psi_j} \bra{\psi_j}}} \\
		       & = \tr_B \rbk{\sum_{i = 1}^n \sum_{j = 1}^N p_i q_j (\ket{\phi_i} \bra{\phi_i} \otimes \ket{\psi_j}\bra{\psi_j})}            \\
		       & = \sum_{i = 1}^N \sum_{j = 1}^N p_i q_j \tr_B(\ket{\phi_i} \bra{\phi_i} \otimes \ket{\psi_j}\bra{\psi_j})                   \\
		       & = \sum_{i = 1}^N \sum_{j = 1}^N p_i q_j \ket{\phi_i} \bra{\phi_i} \tr( \ket{\psi_j}\bra{\psi_j})                            \\
		       & = \rbk{\sum_{i = 1}^N p_i \ket{\phi_i} \bra{\phi_i}} \rbk{\sum_{j = 1}^N q_j \tr(\ket{\psi_j} \bra {\psi_j})}               \\
		       & = \rbk{\sum_{i = 1}^N p_i \ket{\phi_i} \bra{\phi_i}} \tr \rbk{\sum_{j = 1}^N q_j \ket{\psi_j} \bra{\psi_j}}                 \\
		       & = \tau \tr(\sigma)                                                                                                          \\
		       & = \tau
	\end{split}
\end{equation*}

A more interesing example, however, is an \tbf{entangled system}. For instance, let's consider the bell state $$\ket{\Phi^+} := \dfrac{\ket{00} + \ket{11}}{\sqrt 2}$$ We can compute the density operator of this system by following the definition
\begin{equation*}
	\begin{split}
		\rho & = \ket{\Phi^+} \bra{\Phi^+}                                                                \\
		     & = \rbk{\dfrac{\ket{00} + \bra{11}}{\sqrt 2}} \rbk{\dfrac{\ket{00} + \bra{11}}{\sqrt 2}}    \\
		     & = \dfrac{\ket{00} \bra{00} + \ket{11} \bra{00} + \ket{00} \bra{11} + \ket{11} \bra{00}}{2} \\
	\end{split}
\end{equation*}
As we already know, since this system is entangled there is no pair of subsystems $A$ and $B$ that can produce it as a composite tensor product. Nevertherless, let's see what happens when we try to compute $\rho^A$
\begin{equation*}
	\begin{split}
		\rho^A & = \tr_B(\rho)                                                                                                                                                                                   \\
		       & = \tr_B \rbk{\dfrac{\ket{00} \bra{00} + \ket{11} \bra{00} + \ket{00} \bra{11} + \ket{11} \bra{11}}{2}}                                                                                          \\
		       & = \dfrac{\tr_B(\ket{00} \bra{00}) + \tr_B(\ket{11} \bra{00}) + \tr_B(\ket{00} \bra{11} )+ \tr_B( \ket{11} \bra{11})}{2}                                                                         \\
		       & = \dfrac{\tr_B(\ket 0 \bra 0 \otimes \ket 0 \bra 0) + \tr_B(\ket 1 \bra 0 \otimes \ket 1 \bra 0) + \tr_B(\ket 0 \bra 1 \otimes \ket 0 \bra 1 )+ \tr_B( \ket 1 \bra 1 \otimes \ket 1 \bra 1)}{2} \\
		       & = \dfrac{\ket 0 \bra 0 \braket{0|0} + \ket 1 \bra 0 \braket{0|1} + \ket 0 \bra 1 \braket{1|0} + \ket 1 \bra 1 \braket{1|1}}{2}                                                                  \\
		       & = \dfrac{\ket0 \bra 0 + \ket 1 \bra 1}{2}                                                                                                                                                       \\
		       & = \dfrac{I}{2}                                                                                                                                                                                  \\
	\end{split}
\end{equation*}
Now, we observe that $$\tr \rbk{\rbk{\dfrac{I}{2}}^2} = \dfrac{1}{2} < 1$$ and by \cref{mixed prop} this immediately implies that the system is in a \tbf{mixed state}! Observe what just happened: the entangled system is in a \tit{pure state}, because $$\rho = \ket{\Phi^+} \bra{\Phi^+}$$ however, $\rho^A$ (and $\rho^B$ analogously) is mixed! This means that the state of the joint system is known \tit{exactly}, however the state of the first qubit is not maximally known. This strange property is another hallmark of quantum entanglement.

\section{Exercises}

\begin{framedprob}{}
	Show that when the observable is a Hermitian operator, \cref{gen meas post dens} reduces to the \nameref{meas post}.
\end{framedprob}

\solution{
Assuming the \nameref{gen meas post dens}, we can now discuss the spacial case in which the observable is a Hermitian operator. Let $A$ be a Hermitian operator, and suppose that we have a system in a state described by some ensamble $\{p_i, \ket{\psi_i}\}_{i = 1}^N$. By the \nameref{spectral decomp} we know that $$A = \sum_{\lambda \in \mathrm{sp}(A)} \lambda P_\lambda$$ which means that the collection of measurement operators we have to consider is $$A = \{P_\lambda\}_{\lambda \in \mathrm{sp}(A)}$$ This implies that
\begin{equation*}
	\begin{split}
		\Pr[A = \lambda| \rho] & = \tr(P_\lambda^\dag P_\lambda \rho)                               \\
		                       & = \tr(P_\lambda P_\lambda \rho)                                    \\
		                       & = \tr(P_\lambda \rho)                                              \\
		                       & = \tr \rbk{P_\lambda \sum_{i = 1}^N p_i \ket{\psi_i} \bra{\psi_i}} \\
		                       & = \tr \rbk{\sum_{i = 1}^N p_i P_\lambda \ket{\psi_i} \bra{\psi_i}} \\
		                       & = \sum_{i = 1}^N p_i \tr(P_\lambda \ket{\psi_i} \bra{\psi_i})      \\
		                       & = \sum_{i = 1}^N p_i \braket{\psi_i|P_\lambda \psi_i}              \\
	\end{split}
\end{equation*}
Finally, by computing the total probability we get that $$\Pr[A = \lambda| \rho] = \sum_{i = 1}^N p_i \Pr[A = \lambda | \ket{\psi_i}]$$ thus concluding that $$\Pr[A = \lambda| \ket{\psi_i}] = \braket{\psi_i| P_\lambda \psi_i}$$ which indeed matches the definition provided in \nameref{meas post}.
}

\begin{framedprob}[label={deferred meas prob}]{}
    Prove the validity of \nameref{deferred meas post} for an $n$-qubit unitary $U$.
\end{framedprob}

\solution{
    Similar to the 2-qubits case, suppose that the state of the system is described as $$\ket \psi = \sum_{x \in \B^{n + 1}} \alpha_x \ket x$$ We observe that $x \in \B^{n + 1}$ since the first wire has 1 control qubit, and the second register contains the $n$ remaining qubits that will be transformed through $U$. Therefore, the two diagrams are identical as before:

    \begin{figure}[H]
    \centering
    \begin{tabular}{ccc}
        $\vcenter{
            \Qcircuit @C=2em @R=2em {
                & \qw & \meter      & \cctrl{1} & \cw \\
                & \qw & \qw & \gate{U} & \qw \\ 
            }
        }$
        & \qquad &
        $\vcenter{
            \Qcircuit @C=2em @R=2em {
                & \qw & \ctrl{1} & \meter & \cw \\
                & \qw & \gate{U} & \qw & \qw \\ 
            }
        }$
    \end{tabular}
\end{figure}

    % \begin{figure}[H]
    %     \centering
    %     \begin{tabular}{ccc}
    %
    %         % \begin{figure}[H]
    %                 \[
    %                         \Qcircuit @C=2em @R=2em {
    %                         &  \qw & \meter      & \cctrl{1} & \cw \\
    %                         &  \qw & \qw & \gate{U} & \qw \\ 
    %                         }
    %                 \]
    %         % \end{figure}
    %         &\qquad&
    %
    %         % \begin{figure}[H]
    %                 \[
    %                         \Qcircuit @C=2em @R=2em {
    %                         &  \qw & \ctrl{1} & \meter & \cw \\
    %                         &  \qw & \gate{U} & \qw & \qw \\ 
    %                         }
    %                 \]
    %         % \end{figure}
    %
    %     \end{tabular}
    %
    % \end{figure}

    In the first case, we have that
    \begin{equation*}
        \begin{split}
            & \Pr[\mbox{the first qubit collapses to $\ket 0$}] \\ 
            = & \sum_{y \in \B^n}\Pr[\mbox{measure}(\ket{\psi}_0) = \ket{0y}] \\ 
            = & \sum_{y \in \B^n} \abs{\alpha_{0y}}^2
        \end{split}
    \end{equation*}
    and the same reasoning applies for the probability that it collapses to $\ket 1$. Therefore, after the first measurement we have that the state becomes $$\ket \psi \soe{ll}{\sum_{y \in \B^n} \ket{0y} & @ \ \sum_{y \in \B^n} \abs{\alpha_{0y}}^2 \\ \sum_{y \in \B^n} \ket{1y} & @ \ \sum_{y \in \B^n} \abs{\alpha_{1y}}^2}$$ Now, after applying the $U$ gate only if the first qubit has collapsed to $\ket 1$, the final state becomes $$\ket \psi \soe{ll}{\sum_{y \in \B^n} \ket{0y} & @ \ \sum_{y \in \B^n} \abs{\alpha_{0y}}^2 \\ \sum_{y \in \B^n} \ket 1 \otimes U  \ket{y} & @ \ \sum_{y \in \B^n} \abs{\alpha_{1y}}^2}$$

    Differently, in the second case we simply have to distribute the controlled $U$ gate inside the state $\ket \psi$, which indeed yields the same result:
    \begin{equation*}
        \begin{split}
            & \ket \psi \\ 
            = & \sum_{x \in \B^{n + 1}} \alpha_x \ket x \\ 
            \xrightarrow{\mathrm{C-}U(\ket \psi)} & \sum_{x \in \B^{n + 1}} \alpha_x \mbox{C-}U \ket x \\ 
            = & \sum_{\substack{x \in \B^{n + 1} : \\ x = 0y}} \alpha_{0y} \mbox{C-}U \ket {0y} + \sum_{\substack{x \in \B^{n + 1} : \\ x = 1y}} \alpha_{1y} \mbox{C-}U \ket {1y} \\ 
            = & \sum_{y \in \B^n} \alpha_{0y} \ket {0y} + \sum_{y \in \B^n} \alpha_{1y} \ket 1 \otimes U \ket y \\ 
            \xrightarrow{\mathrm{measure}(\ket \psi_0)} & \soe{ll}{\sum_{y \in \B^n} \ket{0y} & @ \ \sum_{y \in \B^n} \abs{\alpha_{0y}}^2 \\ \sum_{y \in \B^n} \ket 1 \otimes U \ket{y} & @ \ \sum_{y \in \B^n} \abs{\alpha_{1y}}^2} \\
        \end{split}
    \end{equation*}
}
