\documentclass[a4paper, 12pt]{report}

\usepackage[dvipsnames]{xcolor}

%%%%%%%%%%%%%%%%
% Set Variables %
%%%%%%%%%%%%%%%%

\def\useItalian{0}  % 1 = Italian, 0 = English

\def\courseName{Quantum Computing}

\def\coursePrerequisites{TODO}

% \def\book{"My book",\\Author 1, ...}

% \def\authorName{Simone Bianco}
% \def\email{bianco.simone@outlook.it}
% \def\github{https://github.com/Exyss/university-notes}
% \def\linkedin{https://www.linkedin.com/in/simone-bianco}

\def\authorName{Alessio Bandiera}
\def\email{alessio.bandiera02@gmail.com}
\def\github{https://github.com/aflaag-notes}
\def\linkedin{https://www.linkedin.com/in/alessio-bandiera-a53767223}

% Do not change

%%%%%%%%%%%%
% Packages %
%%%%%%%%%%%%

\usepackage{../../packages/Nyx/nyx-packages}
\usepackage{../../packages/Nyx/nyx-styles}
\usepackage{../../packages/Nyx/nyx-frames}
\usepackage{../../packages/Nyx/nyx-macros}
\usepackage{../../packages/Nyx/nyx-title}
\usepackage{../../packages/Nyx/nyx-intro}

%%%%%%%%%%%%%%
% Title-page %
%%%%%%%%%%%%%%

\logo{../../packages/Nyx/logo.png}

\if\useItalian1
    \institute{\curlyquotes{\hspace{0.25mm}Sapienza} Universit√† di Roma}
    \faculty{Ingegneria dell'Informazione,\\Informatica e Statistica}
    \department{Dipartimento di Informatica}
    \ifdefined\book
        \subtitle{Appunti integrati con il libro \book}
    \fi
    \author{\textit{Autore}\\\authorName}
\else
    \institute{\curlyquotes{\hspace{0.25mm}Sapienza} University of Rome}
    \faculty{Faculty of Information Engineering,\\Informatics and Statistics}
    \department{Department of Computer Science}
    \ifdefined\book
        \subtitle{Lecture notes integrated with the book \book}
    \fi
    \author{\textit{Author}\\\authorName}
\fi

\title{\courseName}
\date{\today}

% \supervisor{Linus \textsc{Torvalds}}
% \context{Well, I was bored\ldots}

\addbibresource{./references.bib}

%%%%%%%%%%%%
% Document %
%%%%%%%%%%%%

\begin{document}
\maketitle

% The following style changes are valid only inside this scope 
{
	\hypersetup{allcolors=black}
	\fancypagestyle{plain}{%
		\fancyhead{}        % clear all header fields
		\fancyfoot{}        % clear all header fields
		\fancyfoot[C]{\thepage}
		\renewcommand{\headrulewidth}{0pt}
		\renewcommand{\footrulewidth}{0pt}}

	\romantableofcontents
}

\introduction

%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction on Quantum Computation}

\section{The Qubit}

\href{https://en.wikipedia.org/wiki/Quantum_computing}{Quantum computing} is a rapidly developing discipline that explores how the laws of quantum mechanics can be used to \tit{process information}. While classical computation is based on \tit{bits} that take values of either 0 or 1, quantum computation relies on quantum bits, or \tbf{qubits}. A qubit can exist in a \curlyquotes{superposition} of classical states, allowing it to encode richer information than a single bit. Furthermore, qubits can exhibit particular properties that enable forms of information processing with no classical counterpart. Such properties provide the foundation for algorithms that promise to solve certain problems more efficiently than their classical analogues.

The design of quantum algorithms requires a different perspective from that of classical computation. In classical computer science, the majority of widely studied algorithms are \tit{deterministic}, meaning that for a given input they will always produce the \tit{same output}. Some algorithms are \tit{randomized}, making use of probability to achieve efficiency or simplicity, yet even in those cases the computation itself is ultimately classical in nature. In fact, to achieve such \tit{randomness} classical algorithms employ \tbf{pseudo-random number generation}, which must ultimately produce \underline{finite} sequences.

Quantum computation, by contrast, \tit{incorporates probability} at its core. The act of measuring a quantum system does not reveal a single, predetermined result, but rather yields one outcome from a distribution of possible outcomes, with probabilities governed by the system's quantum state. This fundamental probabilistic characteristic distinguishes quantum algorithms from their classical counterparts.

In fact, in the context of quantum computing we are often interested in \tbf{probabilistic algorithms}: for such algorithms, a given input $i$ can lead to a finite set of possible outputs $o_1, \ldots, o_N$, each occurring with an associated probability $p_1, \ldots, p_N$ --- where $\sum_{i = 1}^n{p_i} = 1$.

As previously mentioned, the quantum equivalent of the classical bits are the \tbf{qubit}, but define the qubits we first need to define some preliminary concepts. The following vectors are called \tbf{basis states} $$\ket{0} := \rmat{1 \\ 0} \quad \quad \ket 1 := \rmat{0 \\ 1}$$ and they represent the classical bits 0 and 1 respectively --- the notation above is called \curlyquotes{braket} notation and it will be explored in greater detail in later sections.

So what is a qubit? A qubit is the basic unit of information in quantum computing, which represents a \tbf{superposition} of states simultaneously --- note that we will refer to qubits and their states interchangeably, since the only thing that we care about a qubit is its own state

In practice, the state of a qubit is a vector $$\ket \psi = \alpha \ket 0 + \beta \ket 1 = \alpha \rmat{1 \\ 0 } + \beta \rmat{0 \\ 1} = \rmat{\alpha \\ \beta}$$ where $\alpha, \beta \in \C$ such that $\abs \alpha ^2 + \abs \beta ^2 = 1$ are called \tbf{probability amplitudes}. But why are we talking about probabilities in the first place? The \curlyquotes{true} state of a qubit \tbf{cannot be observed}, and we say that the qubit is in a \tit{superpotion} of $\ket 0$ and $\ket 1$ in the sense that $\alpha$ and $\beta$ describe the probabilities of getting either states once the qubit is measured. This is because to know the value of a qubit we have to \tit{measure it}, and the measurement operation itself will make the qubit \tit{collapse} into either $\ket 0$ or $\ket 1$ with probabilities $\abs \alpha ^2$ and $\abs \beta ^2$ respectively, i.e. $$\Pr[\mbox{measured qubit is $\ket 0$}] = \abs \alpha ^2 \quad \quad \Pr[\mbox{measured qubit is $\ket 1$}] = \abs \beta ^2$$ To use a more compact notation, we will denote this property as follows: $$\alpha \ket 0 + \beta \ket 1 \soe{ll}{\ket 0 & @ \  \abs{\alpha}^2 \\ \ket 1 & @ \ \abs{\beta}^2}$$ where the $@$ notation (read as \curlyquotes{at}) denotes the probabilty of the corresponding outcome. Note that if we measure a collapsed qubit we will keep observing the same state indefinitely.

In reality, to be precise qubits actually collapse into any multiple $z \ket 0$ or $z\ket 1$, where $z \in \C$ is a complex number such that $\abs z = 1$, but this is not relevant from a physical point of view. In fact, for any $\theta$ physicists treat $\ket \psi = \ket 0$ and $\ket {\psi'} = e^{i \theta} \ket 0 $ as the \tit{same physical state}, because probabilities depend on squared magnitudes and thus $$\abs{e^{i \theta} \alpha}^2 = \abs \alpha^2$$ (and the same applies for $\beta$ too) even though $\ket \psi$ and $\ket {\psi'}$ are different vectors mathematically. Therefore, in general we can actually drop the \tbf{global phases} from the qubits entirely.

\section{Qubit operations}

What can we do with qubits other then \tit{measure them}? The operations that can be applied on qubits are restricted to \tbf{unitary transformations}, which are linear maps that preserve the norms --- we will discuss the precise definition in the next chapter. For instance, the identity matrix $I$ is an example of trivial unitary transformation, but also the NOT matrix, which is the following $$\mbox{NOT} := \rmat{0 & 1 \\ 1 & 0}$$ which has the effect of \tit{swapping} the input basis state $$\mbox{NOT} \ket 0 = \ket 1 \quad \quad \mbox{NOT} \ket 1 = \ket 0$$ This matrix behaves as the classical NOT gate with the usual bits in classical computing, in fact will refer to \tit{transformations} and \tit{gates} interchangeably.

More in general, the NOT operation belongs to a family of operation represented by the so called \tbf{Pauli matrices}.

\begin{frameddefn}{Pauli matrices}
	The \tbf{Pauli matrices} are the following four $2 \times 2$ matrices: $$I := \rmat{1 & 0 \\ 0 & 1} \quad \sigma_x := \rmat{0 & 1 \\ 1 & 0} \quad \sigma_y := \rmat{0 & -i \\ i & 0} \quad \sigma_z := \rmat{1 & 0 \\ 0 & -1}$$
\end{frameddefn}

In particular, we observe that the second matrix $\sigma_x$ is exactly the matrix of the NOT operator. We will see the Z and Y operators --- representing the other two matrices, respectively --- as well in later sections.

Another very important transformation is represented by the \tbf{Hadamard gate}, which is the following matrix $$H := \dfrac{1}{\sqrt 2}\rmat{1 & 1 \\ 1 & -1}$$ This matrix has the effect of \curlyquotes{mapping} classical states into superpositions: $$H \ket 0 = \dfrac{1}{\sqrt 2}\rmat{1 & 1 \\ 1 & -1} \rmat{1 \\ 0} = \dfrac{1}{\sqrt 2} \rmat{1 \\ 0} = \dfrac{1}{\sqrt 2} (\ket 0 + \ket 1) \soe{ll}{\ket 0 & @ \  \frac{1}{2} \\ \ket 1 & @ \  \frac{1}{2}}$$ For instance, in this example given $\ket 0$ which represents the classical bit 0, we get a qubit as output of the linear transformation. In general, the operation performed by the Hadamard gate can be represented as follows: $$\forall a \in \{0, 1\} \quad \dfrac{1}{\sqrt 2} \rbk{\ket 0 + (-1)^a \ket 1}$$

As a side note, as we mentioned at the beginning of the chapter quantum mechanics has randomness intrinsically, and since the operation $H \ket 0$ returns a qubit that has 50\% of probability of being either $\ket 0$ or $\ket 1$ once measured, this operation provides a \underline{true} random number generator.

Lastly, can we \tit{represent} qubits graphically? Well, we may be tempted to anwer negatively to this question, since a qubit is described by two complex numbers $\alpha, \beta \in \C$, which implies that we actually need 4 dimensions to correctly represent our vector. However, through polar coordinates we can actually define a graphical representation which allows us to \curlyquotes{picture} qubits, through the so called \tbf{Bloch sphere}. First, consider a qubit $$\ket \psi = \alpha \ket 0 + \beta \ket 1$$ for some $\alpha, \beta \in \C$ such that $\abs{\alpha}^2 + \abs{\beta}^2 = 1$, as usual. Now, recalling that any complex number $z \in \C$ can be actually written as follows $$z = \abs z e^{i \theta}$$ for some angle $\theta$, we can actually rewrite our qubit as follows:
\begin{equation*}
	\begin{alignedat}{2}
		\ket \psi & = \abs \alpha e^{i \theta_\alpha} \ket 0 + \abs \beta e^{i \theta_\beta} \ket 1                             &                                                                            \\
		          & = e^{i \theta_\alpha} \rbk{\abs \alpha \ket 0 + \abs \beta e^{i \rbk{\theta_\beta - \theta_\alpha}} \ket 1} &                                                                            \\
		          & = \abs \alpha \ket 0 + \abs \beta e^{i \rbk{\theta_\beta - \theta_\alpha}} \ket 1                           & \quad \rbk{\mbox{$e^{i \theta_\alpha}$ is a global phase}}                 \\
		          & = \abs \alpha \ket 0 + e^{i \varphi} \ket 1                                                                 & \quad (\mbox{let $\varphi: = \theta_\beta - \theta_\alpha \in [0, 2\pi)$}) \\
	\end{alignedat}
\end{equation*}
and finally, since $\abs{\alpha}^2 + \abs{\beta}^2 = 1$, is precisely the equation of the circumference of radius 1, we usually rewrite the last equation as follows: $$\ket \psi = \cos{\rbk{\dfrac{\theta}{2}}} \ket 0+ e^{i \varphi} \sin{\rbk{\dfrac{\theta}{2}}} \ket 1$$ where $\theta \in [0, \pi], \varphi \in [0, 2\pi)$. This formulation of the qubit $\ket \psi$ allows us to represent it inside the Bloch sphere: in fact, in this formulation the qubit is normalized, which implies that it will lie on a 3 dimensional unit sphere, and it is described by the two phases $\theta$ and $\varphi$ --- in 2D polar coordinates there is only 1 angle, as in 3D polar coordinate there are two angles.

\centeredimage[The Bloch sphere representing some qubit.]{0.2}{../assets/bloch.png}

\subsection{The tensor product}

So far we have dealt with only one qubit at a time, but what if we have two qubits? First, let's look at the classical counterpart. If we take two bits $a, b \in \{0, 1\}$, we can represent 4 possible binary numbers, namely 00, 01, 10 and 11, which we can algebraically obtain by computing the usual cartesian product $$\{0, 1\}^2 = \{0, 1\} \times \{0, 1\} = \{(0, 0), (0, 1), (1, 0), (1, 1)\}$$ Note that in the cartesian products it holds that:

\begin{itemize}
	\item the length of the tuples of the product is linear w.r.t. the number of factors of the cartesian products --- in this case, 2
	\item each element of a tuple is \tit{independent} from the other elements of the tuple
\end{itemize}

How can we evaluate all the possible states that two qubits can represent, instead? To answer this question, we need to introduce a new operator, which is called \tbf{tensor product}. Given two vectors $\rmat{a \\ b}$ and $\rmat{c \\ d}$, their tensor product is defined as follows $$\rmat{a \\ b} \otimes \rmat{c \\ d} := \rmat{ac \\ ad \\ bc \\ bd}$$ Hence, consider two qubits $$\ket \psi = \alpha_0 \ket 0 + \alpha_1 \ket 1 = \rmat{\alpha_0 \\ \alpha_1} \quad \quad \ket \phi = \beta \ket 0 + \beta_1 \ket 1 = \rmat{\beta_0 \\ \beta_1}$$ To obtain all the possible states of $\ket \psi$ and $\ket \phi$ we just have to compute the tensor product between them, which is
\begin{equation*}
	\begin{split}
		\ket \psi \otimes \ket \phi & = \rmat{\alpha_0           \\ \alpha_1} \otimes \rmat{\beta_0 \\ \beta_1} \\
		                            & = \alpha_0 \beta_0 \rmat{1 \\ 0 \\ 0 \\ 0 } + \alpha_0 \beta_1 \rmat{0 \\ 1 \\ 0 \\ 0} + \alpha_1 \beta_0 \rmat{0 \\ 0 \\ 1 \\ 0} + \alpha_1 \beta_1 \rmat{0 \\ 0 \\ 0 \\ 1}
	\end{split}
\end{equation*}
At the beginning of the chapter we defined $\ket 0$ and $\ket 1$ to be $\rmat{0 \\ 1}$ and $\rmat{1 \\ 0}$ without providing an explaination; now that we are dealing with more than 2 dimensions we can show why such names are used. In fact, we will use the following naming convention $$\ket{00} := \rmat{1 \\ 0 \\ 0 \\ 0 } \quad \ket {01} := \rmat{0 \\ 1 \\ 0 \\ 0} \quad \ket{10} := \rmat{0 \\ 0 \\ 1 \\ 0} \quad \ket{11} := \rmat{0 \\ 0 \\ 0 \\ 1}$$ and in general it holds that $$\ket{\mbox{bin}(i)} = e_i$$ where $\mbox{bin}(i)$ represents for the binary representation of $i$, and $e_i$ is the $i$-th vector of the canonical basis. This implies that we can rewrite the previous tensor product as follows: $$\ket \psi \otimes \ket \phi = \alpha_0 \beta_0 \ket{00} + \alpha_0 \beta_1 \ket{01} + \alpha_1 \beta_0 \ket{10} + \alpha_1 \beta_1 \ket {11} = \sum_{i, j \in \{0, 1\}}{\alpha_i \beta_j \ket{ij}}$$ As a final note, it can be easily proven that $$\forall i, j \in \{0, 1\} \quad \ket i \otimes \ket j = \ket{ij}$$

For example, given two qubits $$\ket \phi = \dfrac{1}{\sqrt 2} (\ket 0 + \ket 1) \quad \ket \psi = \dfrac{1}{\sqrt 2} (\ket 0 + \ket 1)$$ we get that
\begin{equation*}
	\begin{split}
		\ket \psi \otimes \ket \phi & = \rmat{\tfrac{1}{\sqrt 2}                                                   \\ \tfrac{1}{\sqrt 2}} \otimes \rmat{\tfrac{1}{\sqrt 2} \\ \tfrac{1}{\sqrt 2}} \\
		                            & = \rmat{\tfrac{1}{2}                                                         \\ \tfrac{1}{2} \\ \tfrac{1}{2} \\ \tfrac{1}{2}} \\
		                            & = \dfrac{1}{2}(\ket{00} + \ket{01} + \ket{10} + \ket{11})                    \\
		                            & \soe{ll}{\ket 0 \mbox{and} \ket 0                         & @ \ \tfrac{1}{4} \\ \ket 0 \mbox{and} \ket 1 & @ \ \tfrac{1}{4} \\ \ket 1 \mbox{and} \ket 0 & @ \ \tfrac{1}{4} \\ \ket 1 \mbox{and} \ket 1 & @ \ \tfrac{1}{4}}
	\end{split}
\end{equation*}
where the probabilities at the end refer to the two individual qubits. To recap, in general the tensor product $\ket \psi \otimes \ket \phi$ of two qubits encodes the superposition of 4 basis states, namely $\ket {00}$, $\ket{01}$, $\ket{10}$ and $\ket {11}$.

Moreover, the following property can be proved easily.

\begin{framedprop}{Distributive property of $\otimes$}
	Given three qubits $\ket \psi, \ket \phi$ and $\ket \chi$, it holds that $$(\ket \psi + \ket \phi) \otimes \ket \chi = \ket \psi \otimes \ket \chi + \ket \phi \otimes \ket \chi$$
\end{framedprop}

\subsection{Controlled operations}

Another familyh of very important gates in quantum computing is the \tit{controlled operations}. The first controlled operation that we are going to discuss is the so called \tbf{Controlled NOT (CNOT)} gate, which is defined as follows:

\begin{center}
	\begin{tabular}{cc|c}
		\hline
		$a$ & $b$ & $\mbox{CNOT}(a, b)$ \\
		\hline\hline
		0   & 0   & 0                   \\
		\hline
		0   & 1   & 1                   \\
		\hline
		1   & 0   & 1                   \\
		\hline
		1   & 1   & 0                   \\
		\hline
	\end{tabular}
\end{center}

In fact, the names comes from the fact that the first input $a$ is called \tit{control bit}, which if set to 1 will flip the \tit{target bit} $b$ --- in fact, in its implementation what actually happens is that $b$'s wire itself is flipped. Therefore, in general we will write that $$\mbox{CNOT}(a, b) = (a, a \oplus b)$$

First, we observe that this function is clearly not invertible, since for instance if we know that the output is 0 we still need the input $a$ to evaluate if $b$ was 0 or 1. Hence, to solve this issue we usually pair the output of CNOT with $a$ itself, so that we can actually invert the computation.

Moreover, so far we only dealt with transformation that only expected one qubit argument as input, but the CNOT gate would certainly need 2 inputs to perform any computation, so how do we provide two inputs to it? As we showed before, we konw that $$\forall i, j \in \{0, 1\} \quad \ket i \otimes \ket j = \ket{i j}$$ which directly implies that the vector $\ket{ij}$ encapsulated two qubits at once without ambiguity. Hence, we can actually leverage the tensor product to provide the input to the CNOT matrix, such that the quantum CNOT will behave as follows $$\mbox{CNOT}(\ket a \otimes \ket b) = \ket a \otimes \ket{a \oplus b}$$ Hence, the matrix that behaves as such is the following $$\mbox{CNOT} := \rmat{1 & 0 & 0 & 0 \\ 0 & 1 & 0 & 0 \\ 0 & 0 & 0 & 1 \\ 0 & 0 & 1 & 0}$$ which expects a $4 \times 1$ input vector, and outputs a $4 \times 1$ output vector as well.

Laslty, as for the CNOT operator, we can actually define controlled operators for both Y and Z, which are respectively called CY and CZ operators.

\subsection{Quantum circuits}

Now that we introduced a couple of quantum gates, we can show how computation is actually represented in quantum computing. For instance, consider the following picture:

\centeredimage[The NOT gate.]{0.8}{../assets/not.png}

In this example, we have 1 single input qubit, namely $q$, and the box labeled with an $X$ represents the NOT gate. We observe that, by convetion, all qubits in quantum circuits are assumed to be set to $\ket 0$.

In the following example, instead, it is represented how the Hadamard gate looks like in quantum circuits.

\centeredimage[The Hadamard gate.]{0.8}{../assets/h.png}

Moreover, if we consider two qubits as inputs $q_0$ and $q_1$, we can represent the CNOT operator as follows:

\centeredimage[The CNOT gate.]{0.8}{../assets/cnot.png}

We observe that $q_1$ then becomes the output of the CNOT operation, and $q_0$ remains unchanged. Lastly, the measurement operation is represented with the following picure:

\centeredimage[The measure operation.]{0.8}{../assets/meas.png}

In particular, in this cirtuit we see that:

\begin{itemize}
	\item the vertical \curlyquotes{double line} reprents \tit{classical bits}
	\item the number 1 next to the label \curlyquotes{meas} indicates the number of qubits that have been measured
	\item the number 0 is the index of the measured qubit
\end{itemize}

\centeredimage[An exmaple of measurement of 2 qubits.]{0.8}{../assets/meas2.png}

Lastly, another very important circuit is the following, which produces the so called \tbf{Greenberger-Horne-Zeilinger (GHZ)} state

\centeredimage[The GHZ quantum circuit.]{0.8}{../assets/ghz.png}

which is represented as follows $$\ket{\mbox{GHZ}} := \dfrac{1}{\sqrt 2}\rbk{\ket{000} + \ket{111}}$$

\section{Peculiarities of quantum mechanics}

\subsection{Quantum entanglement}

Consider the following quantum state $$\ket \psi = \dfrac{1}{\sqrt 2}\rbk{\ket {01} + \ket {10}}$$ Can this state be rewritten as the tensor product of two distinct quantum states? We observe that for this to be possible we would require some complex values $\alpha_0, \alpha_1, \beta_0, \beta_1$ such that $$\soe{l}{\alpha_0 \beta_0 = \alpha_1 \beta_1 = 0 \\ \alpha_0 \beta_1 = \alpha_1 \beta_0 = \tfrac{1}{\sqrt 2}}$$ but $\alpha_0 \beta_0 = 0$ implies that at least one between $\alpha_0$ and $\beta_0$ has to be 0, meaning that at least one between $\alpha_0\beta_1$ and $\alpha_1\beta_0$ has to be 0 as well. This proves that there is no such pair of quantum states which can describe $\ket \psi$ through the tensor product operation. In fact, we see that $$\ket \psi = \dfrac{1}{\sqrt 2}\rbk{\ket{01} + \ket{10}}  \soe{ll}{\ket{01} & @ \ \tfrac{1}{2} \\ \ket{10} & @ \ \tfrac{1}{2}}$$ Indeed, this particular state we chose is one of the so called \tbf{Bell states}.

\begin{frameddefn}{Bell states}
	The following are the four \tbf{Bell states}: $$\ket{\Phi^+} := \dfrac{1}{\sqrt 2}\rbk{\ket{00} + \ket{11}}$$ $$\ket{\Phi^-} := \dfrac{1}{\sqrt 2}\rbk{\ket{00} - \ket{11}}$$ $$\ket{\Psi^+} := \dfrac{1}{\sqrt 2}\rbk{\ket{01} + \ket{10}}$$ $$\ket{\Psi^-} := \dfrac{1}{\sqrt 2}\rbk{\ket{01} - \ket{10}}$$
\end{frameddefn}

Whenever we have a state $\ket \psi$ that cannot be represented as the tensor product of two simpler quantum states, we say that the state is \tbf{entangled} --- or that its possible outcomes are entangled. In particular, entangled states describe a very weird phenomenon first proposed as a thought experiment in a groundbreaking paper by \tbf{Einstein, Podolsky and Rosen (EPR)} \cite{epr}, the so called \tbf{EPR paradox}.

The thought experiment involves a pair of particles prepared in such \tit{entangled state}. Einstein, Podolsky, and Rosen pointed out that, in this state, if the position of the first particle were measured, the result of measuring the position of the second particle \tit{could be predicted}. If instead the momentum of the first particle were measured, then the result of measuring the momentum of the second particle could be predicted. They argued that no action taken on the first particle could instantaneously affect the other, since this would involve information being transmitted faster than light, which is impossible according to the theory of relativity. Einstein famously called this phenomenon \curlyquotes{spooky action at a distance}, and to the best of our knowledge the theory of quantum mechanics says that if we have two engangled states, and measure one of them --- for instance, say that it collapses to $\ket 0$ --- the other state will \tbf{instantaneously} collapse to $\ket 1$ (and viceversa). They are \tit{perfectly anti-correlated}, even if the two states are phisically light-years away from each other.

To be precise, entanglement is \tit{not} a way to tranfer information --- collapsing happens instantaneously, which would violate the fact that nothing can travel faster than light, not even information. Instead, it is a way to share correlations nonlocally. In fact, it is a phenomenon that regards the \tit{whole quantum system} considered: for instance, given three qubits $q_0, q_1, q_2$, such that $q_1$ and $q_2$ are entangled, we might want to only measure $q_0 \otimes q_1$, which in turn will make $q_2$ collapse into some quantum state that has to be mathematically computed in order to be predicted --- this will be more clear when we will describe \tbf{quantum teleportation} in \cref{quantum teleportation}.

To finish off this section, we can actually generate entangled states, or \tbf{EPR pairs} for short, through quantum gates as such:

\centeredimage[The quantum circuit for $\ket{\Phi^+}$.]{0.8}{../assets/epr.png}

In particular, we observe that the first Hadamard gate will transform $\ket 0$ to $\dfrac{1}{\sqrt 2}\rbk{\ket 0 + \ket 1}$, and through the CNOT operation we obtain $$\ket{\Phi^+} := \dfrac{1}{\sqrt 2}\rbk{\ket{00} + \ket{11}}$$

\subsection{No-cloning theorem}

An operation that we take for granted in classical computation is the possibility to \tit{copy} the value of a bit: if Alice has two bits $x, y \in \{0, 1\}$, and she wants to copy the value of $x$ into $y$, she can do it without any issues. However, in quantum mechanics this is \tit{not} possible, because it would quite literally violate the laws of physics --- as far as we understand it.

In 1982 \textcite{nocloning} proved the so called \tbf{no-cloning theorem}, which states that it is impossible to create an independent and identical copy of an arbitrary \tit{unknown} quantum state.

\begin{framedthm}{No-cloning theorem}
	There is no quantum transformation that copies an unknown quantum state.
\end{framedthm}

\begin{proof}
	by way of contradiction, suppose that there exists such a transformation CP that is able to copy an unknown quantum state --- and in particular, we observe that such transformation would have to be linear. But clearly, in order to have a copy we need to actually \tit{store} it somewhere, so we can assume that CP has to take two inputs, one being the state that we want to copy and the other one being the state that we want to replace with the copy of the first one. In other words, we are assuming that $$\exists y \forall x \quad \mbox{CP}(x \otimes y) = x \otimes x$$ Now, through some algebraic manipulation we get that
	\begin{equation*}
		\begin{alignedat}{2}
			       & \exists y \forall x \quad \mbox{CP}(x \otimes y) = x \times x                                                  &                                         \\
			\equiv & \exists y \forall x, a \quad \mbox{CP}((x + a) \otimes y) = (x + a) \otimes (x + a)                            &                                         \\
			\equiv & \exists y \forall x, a \quad \mbox{CP}(x \otimes y + a \otimes y) = (x + a) \otimes (x + a)                    & (\mbox{by distributivity of $\otimes$}) \\
			\equiv & \exists y \forall x, a \quad \mbox{CP}(x \otimes y) + \mbox{CP}(a \otimes y) = (x + a) \otimes (x + a)         & (\mbox{by linearity of CP})             \\
			\equiv & \exists y \forall x, a \quad x \otimes x + a \otimes a = x \otimes x + x \otimes a + a \otimes x + a \otimes a & \quad (\mbox{by definition of CP})      \\
			\equiv & \exists y \forall x, a \quad \mathbf 0 = x \otimes a + a \times x
		\end{alignedat}
	\end{equation*}
	which should be true for every $x$ and every $a$, however it does not hold for $x = \ket 0$ and $a = \ket 1$, thus raising a contradiction $\lightning$.
\end{proof}

The no-cloning theorem represents an inherent limitation of quantum computation, and has direct impacts on \tbf{quantum cryptography} and \tbf{quantum error correction}, but must importantly it directly impacts a phenomenon called \tbf{quantum teleportation}

\subsection{Quantum teleportation} \label{quantum teleportation}

So far we saw that quantum states cannot be cloned, but can we at least \tit{send} them? Suppose that Alice wants to send Bob $\ket \psi$, described by some $\alpha$ and $\beta$. Clearly, the only thing that Bob has to receive are indeed the probability amplitudes of $\ket \psi$, so even if Alice cannot clone her quantum state, nothing prevents her to build a quantum circuit which \tit{destroys} her $\ket \psi$ but does allow Bob to receive $\alpha$ and $\beta$. This process is called \tbf{quantum teleportation}, and can be achieved through the following algorithm.

\begin{framedalgo}{Quantum teleportation algorithm}
    Given three qubits $q_0$, $q_1$ and $q_2$, the algorithm moves the state of $q_0$ into $q_2$ \\
    \hrule

    \quad
    \begin{algorithmic}[1]
        \Function{QuantumTeleportation}{$q_0$, $q_1$, $q_2$}
            \State $q_1 = H(q_1)$
            \State $q_2 = CX(q_1, q_2)$ \Comment{entangle $q_1$ and $q_2$}
            \State $q_1 = CX(q_0, q_1)$
            \State $q_0, q_1 = \mbox{measure}(q_0, q_1)$
            \If{$q_1 == \ket 1$}
                \State $q_2 = X(q_2)$
            \EndIf
            \If{$q_0 == \ket 1$}
                \State $q_2 = Z(q_2)$
            \EndIf
            \State \tbf{return} $q_2$
        \EndFunction
    \end{algorithmic}
\end{framedalgo}

\centeredimage[The Quantum Teleportation circuit.]{0.8}{../assets/telep.png}

There is quite a lot to unpack in this diagram. First, the quantum state that we want to teleport is $q_0$ in this diagram, and it will be teleported in $q_2$ at the end of the quantum computation.

In the first part of the circuit, we see that $q_1$ and $q_2$ are entangled (in an initial stage of the process, not performed by Alice nor Bob) in the Bell state $\ket{\Phi^+}$ thanks to the Hadamard and the CNOT gates --- as we described in previous sections. In a real-world scenario, we will assume that $q_1$ and $q_2$ are given to Alice and Bob respectively (through some \tbf{quantum channel} such as optical fibers or free-space links in order to avoid \tit{decoherence}), and quantum mechanics will guarantee that the teleportation will work even our two protagonists are thousands of kilometers away from each other.

After creating and entangling $q_1$ and $q_2$ (say for instance in a lab as preparation), we have the part of circuit that concerns Alice: in fact, she must apply a CNOT to her entangled qubit $q_1$, controlled by $q_0$, and then apply a Hadamard transformation to $q_0$. At this point, the circuit must apply a measurement to both $q_0$ and $q_1$ --- and in particular, this operation will \tit{destroy} the original state as previously anticipated.

Finally, it's Bob's turn: to obtain the original quantum state of $q_0$, the only thing he needs to do is first apply a CNOT to his entangled qubit $q_2$, controlled by $q_1$'s outcome, followed by an application of a CZ, controlled by $q_0$'s outcome instead --- we observe that this part is indicated in the diagram through the \texttt{0x2} and \texttt{0x1} labels respectively. In fact, in the label \texttt{0xX} the number \texttt X represents the hexadecimal representation of the binary number obtained by joining the classical bits all together --- for instance, in this circuit we have that 2 represents 10, meaning that only $q_1$ will be checked in the condition, and 1 represents 01, which means that only $q_0$ will be the control bit.

To show why the circuit actually works, we first need to discuss how computations with qubits and quantum gates is performed. In particular, we do not consider qubits \tit{individually}, but instead we consider the whole \tbf{system} of qubits, i.e. $q_0 \otimes q_1 \otimes q_2$ simultaneously, and thus we will perform calculations as such. In fact, even if the drawing represents Alice's measurements of $q_0$ and $q_1$ independently, what happens in reality is that Alice is going to measure $q_0 \otimes q_1$ such that $q_3$ will collapse into its opposite.

Finally, we are ready to prove the correctness of the quantum teleportation circuit. First, we need to represent the initial quantum state, namely
\begin{equation*}
	\begin{split}
		  & q_0 \otimes q_1 \otimes q_2                                                                                                                 \\
		= & \ket \psi \otimes \ket{\Phi^+}                                                                                                              \\
		= & (\alpha \ket{0}_{0} + \beta \ket{1}_{0}) \otimes \dfrac{1}{\sqrt 2}(\ket{00}_{12} + \ket{11}_{12})                                          \\
		= & \dfrac{1}{\sqrt 2} [\alpha \ket{0}_{0} \otimes (\ket{00}_{12} + \ket{11}_{12}) + \beta \ket{1}_{0} \otimes (\ket{00}_{12} + \ket{11}_{12})]
	\end{split}
\end{equation*}
where the notation $\ket{00}_{12}$ represents for example that we are considering $q_1$ and $q_2$'s parts of states, respectively. From now on, we will omit the $\otimes$ symbol --- as for the \curlyquotes{normal} product. The next step is to apply the CNOT on $q_0$ and $q_1$, therefore the quantum state of the system becomes the following: $$\dfrac{1}{\sqrt 2}\sbk{\alpha \ket{0}_{0} (\ket{00}_{12} + \ket{11}_{12}) + \beta \ket{1}_{0} (\ket{10}_{12} + \ket{01}_{12})}$$ Next, we have to apply the Hadamard gate on $q_0$, which turns the quantum state into the following
\begin{equation*}
	\begin{split}
		  & \dfrac{1}{\sqrt 2} \sbk{
			\alpha \dfrac{1}{\sqrt 2} ( \ket{0}_{0} + \ket{1}_{0} ) ( \ket{00}_{12} + \ket{11}_{12} )
			+ \beta \dfrac{1}{\sqrt 2} ( \ket{0}_{0} - \ket{1}_{0} ) ( \ket{10}_{12} + \ket{01}_{12} )
		}                            \\
		= & \dfrac{1}{2} \sbk{
			\alpha ( \ket{000}_{012} + \ket{011}_{012} + \ket{100}_{012} + \ket{111}_{012} )
			+ \beta ( \ket{010}_{012} + \ket{001}_{012} - \ket{110}_{012} - \ket{101}_{012} )
		}                            \\
		= & \dfrac{1}{2} \sbk{
			\ket{00}_{01} ( \alpha \ket{0}_{2} + \beta \ket{1}_{2} )
			+ \ket{01}_{01} ( \beta \ket{0}_{2} + \alpha \ket{1}_{2} )  + \ket{10}_{01} ( \alpha \ket{0}_{2} - \beta \ket{1}_{2} )
			+ \ket{11}_{01} ( \alpha \ket{1}_{2} - \beta \ket{0}_{2} )
		}                            \\
		= & \dfrac{1}{2} \sbk{
			\ket{00}_{01} \ket{\psi}_{2}
			+ \ket{01}_{01} X \ket{\psi}_{2}
			+ \ket{10}_{01} Z \ket{\psi}_{2}
			+ \ket{11}_{01} XZ \ket{\psi}_{2}
		}
	\end{split}
\end{equation*}
Finally, Alice will perform the measurement on $q_0$ and $q_1$, and what will happen is that the \tit{whole} quantum state of the quantum circuit will collapse as follows: $$\soe{ll}{\ket{00}_{01} \otimes \ket \psi_2 & @ \ \tfrac{1}{4} \\ \ket{01}_{01} \otimes X \ket \psi_2 & @ \ \tfrac{1}{4} \\ \ket{10}_{01} \otimes Z \ket \psi_2 & @ \ \tfrac{1}{4} \\ \ket{11}_{01} \otimes XZ \ket \psi_2 & @ \ \tfrac{1}{4}}$$ Note that to perform the measurement operation on just $q_0$ and $q_1$ we would need some mathematical tools that are outside the scope of this course, therefore we will only show the probabilities of the outcomes as presented above. In fact, fom this table we can easily explain the last part of the quantum teleportation circuit, i.e. Bob's part, as shown below.

\begin{center}
	\begin{tabular}{c|c|c}
		\hline
		Alice's outcome & Bob's part & Bob's result                 \\
		\hline\hline
		0 and 0         & $I$        & $\ket \psi$                  \\
		\hline
		0 and 1         & $X$        & $XX \ket \psi = \ket \psi$   \\
		\hline
		1 and 0         & $Z$        & $ZZ \ket \psi = \ket \psi$   \\
		\hline
		1 and 1         & $XZ$       & $XZXZ \ket \psi = \ket \psi$ \\
		\hline
	\end{tabular}
\end{center}

Lastly, note that even if the mathematical calculations don't highlight the fact that $q_0$ and $q_1$ are measured, these two bits are effectively \tit{destroyed} as we already described. In fact, $q_2$ will be the only usable qubit after the whole process --- for instance, nothing prevents us from applying more transformations on the state $\ket{00}_{01} \otimes \ket \psi_2$ \tit{mathematically}, but in reality $q_0$ and $q_1$ are not usable anymore.

\chapter{Mathematical foundations}

Now that we laid down some preliminary concepts regarding quantum machanics and quantum computaions, we need to discuss some \tbf{mathematical foundations} in order to progress and achieve a deeper meaning of the tools that we are going to use. In fact, at the end of this chapter we will state precisely the postulates of quantum mechanics, but in order to understand them we need to introduce some crucial definitions.

We will start our mathematical discussion with the definition of \tbf{scalar product} --- we will assume the definitions of vector space, basis and linear independence are already known by the reader.

\begin{frameddefn}{Scalar product}
	Given a scalar product vector space $V$, a \tbf{scalar product} $\funcmap{\braket{\cdot , \cdot }}{V \times V}{\C}{(v, w)}{\braket{v,w}}$ is a function that satisfies the following properties:

	\begin{itemize}
		\item $\forall u, v, w \in V, \alpha, \beta \in \C \quad \braket{u,\alpha v + \beta w} = \alpha \braket{u|v} + \beta \braket{u| w}$
		\item $\forall u, v \in V \quad \overline{\braket{u,v}} = \braket{v, u}$ --- where $\overline z$ is the conjugate of $z \in \C$
		\item $\forall u \in U \quad \braket{u, u} \ge 0$ and $\braket{u, u} = 0$ if and only if $u = 0$
	\end{itemize}
\end{frameddefn}

Scalar products are also called \tit{inner product}, and are used to define many other tools on top of the vector space considered.

\begin{framedprop}{}
	For any scalar product vector space $V$, any scalar product satisfies the following property: $$\forall u, v, w \in V, \alpha, \beta \in \C \quad \braket{\alpha u + \beta v, w} = \overline \alpha \braket{u, w} + \overline \beta \braket{v, w}$$
\end{framedprop}

\begin{proof}
	TODO \todo{TODO}
\end{proof}

In particular, the scalar product that we are going to use for our purposes is defined as follows: $$\forall u, v \in \C^n \quad \braket{u, v} = \sum_{i = 1}^n{\overline{u_i} v_i}$$ In fact, we can prove that this is indeed a scalar product as follows:

\begin{itemize}
	\item TODO \todo{TODO}
	\item TODO \todo{TODO}
	\item TODO \todo{TODO}
\end{itemize}

From now on, when we refer to a \curlyquotes{scalar product} we will refer to this particular definition.

We are finally ready to explain the \curlyquotes{braket} that we used from the beginning of the previous chapter. This notation was invented by the Nobel Prize in Physics \href{https://it.wikipedia.org/wiki/Paul_Dirac}{Paul Dirac}, and it works as follows: first, observe that our scalar product can be rewritten as follows $$\braket{u, v} = \rmat{\overline{u_1} \cdots \overline{u_n}} \rmat{v_1 \\ \vdots \\ v_n}$$ To be precise, this product would yield a $1 \times 1$ matrix, which can be interpreted as a scalar. Through Dirac notation, we will write $$\braket{u, v} = \braket{u | v}$$ where $\bra u$ is called \tbf{bra}, and $\ket v$ is called \tbf{ket} (as in \curlyquotes{bra-ket}). In other words, we have that $\ket v$ is just a regular column vector $v \in V$ $$\ket v = \rmat{v_1 \\ \vdots \\ v_n}$$ defined over some scalar product vector space $V$, while $\bra u$ is a \tit{linear map} that acts as follows: $$\funcmap{\bra \cdot}{V}{\overline V}{\rmat{u_1 \cdots u_n}}{\rmat{\overline{u_1} \cdots \overline{u_n}}}$$

\begin{framedthm}{Cauchy-Schwarz inequality}
	Given a scalar product vector space $V$, it holds that $$\forall u, v \in V \quad \abs{\braket{u|v}} \le \sqrt{\braket{u|v} \braket{u|v}}$$ where the equality holds if and only if $u$ and $v$ are linearly independent.
\end{framedthm}

Moreover, our scalar product induces a \tbf{norm}, which is defined as follows.

\begin{frameddefn}{Norm}
	Given a scalar product vector space $V$, the \tbf{norm} of a vector $v \in V$ is defined as follows $$\norm v = \sqrt{\braket{v|v}}$$
\end{frameddefn}

As usual, two vectors $u, v \in V$ are said to be \tbf{orthogonal} if $\braket{u|v} = 0$. This allows us to define orthonormal bases.

\begin{frameddefn}{Orthonormal basis}
	Given a scalar product vector space $V$, a basis $\{e_1, \ldots, e_n\}$ is said to be \tbf{orthonormal} if $$\forall i, j \in [n] \quad \braket{e_i | e_j} = \delta_{ij}$$ where $\delta_{ij} = \soe{ll}{1 & i = j \\ 0 & i \neq j}$ is called \tbf{Kronecker delta}.
\end{frameddefn}


Let's see the Dirac notation in action. Consider an orthonormal basis $\{e_1, \ldots, e_n\}$ for some scalar product vector space $V$; by definition, we know that we can write any vector $u \in V$ as follows $$u = \sum_{i = 1}^n{\alpha_i e_i}$$ for some coefficients $\alpha_1, \ldots, \alpha_n \in \C$. Now, we observe that for all $i \in [n]$
\begin{equation*}
	\begin{alignedat}{2}
		\braket{e_i|u} & = \braket{e_i|\sum_{j = 1}^n{\alpha_j e_j}}                      & \\
		               & = \abk{e_i \middle|\alpha_1e_1 + \ldots + \alpha_n e_n}               & \\
		               & = \alpha_1 \braket{e_i|e_1} + \ldots + \alpha_n \braket{e_i|e_n} & \\
		               & = \sum_{j = 1}^n{\alpha_j\braket{e_i | e_j}}                     & \\
		               & = \sum_{j = 1}^n{\alpha_j \delta_{ij}}                           & \\
		               & = \alpha_i                                                       & \\
	\end{alignedat}
\end{equation*}
Indeed, with the scalar product we can compute the projection of $u$ onto the $i$-th vector of the basis. Hence, we can rewrite the first equation as follows: $$\ket u = \sum_{i = 1}^n{\alpha_i \ket{e_i}} = \sum_{i = 1}^n{\braket{e_i|u} \ket{e_i}}$$ In particular, we observe that $$\ket u = \sum_{i = 1}^n{\ket{e_i} \braket{e_i|u}} \implies I = \sum_{i = 1}^n{\ket{e_i} \bra{e_i}}$$ which is a famous identity in quantum mechanics called \tbf{resolution of the identity}. As a final note, by the properties of scalar products we also have that $$\braket{v|u} = \abk{v \middle| \sum_{i = 1}^n{\braket{e_i|u} \ket{e_i}}} = \sum_{i = 1}^n {\braket{v|e_i} \braket{e_i|u}}$$

\begin{framedprop}{}
    Given a scalar product vector space $V$, it holds that $$\forall u, v, w \in V \quad \braket{u|v} \ket w = (\ket w \bra u) \ket v$$
\end{framedprop}

\begin{proof}
    TODO \todo{TODO}
\end{proof}

\section{Hilbert spaces}

Now that we covered Dirac notation, we can describe what are \tbf{Hilbert spaces} --- we will see why we care about this particular type of vector spaces later in the chapter. First, consider the following definitions.

\begin{frameddefn}{Weak convergence}
	Given a scalar product vector space $V$, and a vector sequence $\{v_m\}_{m \in \N}$ defined over $V$, we say that the sequence \tbf{converges weakly} to a vector $v \in V$ if $$\forall w \in V \quad \lim_{m \to + \infty}{\braket{v_m|w}} = \braket{v|w}$$
\end{frameddefn}

In other words, this type ocf convergence requires all projections of $v_m$ along any fixed direction $w$ to approach the projection of $v$. Differently, the next type of convergence is more strict.

\begin{frameddefn}{Strong convergence}
	Given a scalar product vector space $V$, and a vector sequence $\{v_m\}_{m \in \N}$ defined over $V$, we say that the sequence \tbf{converges strongly} to a vector $v \in V$ if $$\lim_{m \to + \infty}{\norm{v - v_m}} = 0$$
\end{frameddefn}

In fact, this type of convergence requires the actual vectors of the sequence to get close \tit{in norm} to $v$. We observe the following proposition.

\begin{framedprop}{}
	Given a scalar product vector space $V$, and a vector sequence $\{v_m\}_{m \in \N}$ defined over $V$, if the sequence converges strongly to some vector $v \in V$, it holds that

	\begin{itemize}
		\item the sequence also converges weakly
		\item the scalar products defined over $V$ are continuous, i.e. $$\forall u, v \in V \quad \braket{u|v} = \lim_{m \to + \infty}{\braket{u|v_m}}$$
	\end{itemize}
\end{framedprop}

\begin{frameddefn}{Cauchy sequence}
	Given a scalar product vector space $V$, and a vector sequence $\{v_m\}_{m \in \N}$ defined over $V$, we say that the sequence is a \tbf{Cauchy sequence} if it holds that $$\forall \varepsilon > 0 \quad \exists n_\varepsilon \in \N \quad \forall n, m > n_\varepsilon \quad \norm{v_n - v_m} < \varepsilon$$
\end{frameddefn}

For example, let's consider the space $\R^2$ equipped with the Euclidean norm $$\norm v =  \sqrt{x^2 + y^2}$$ Then, if we consider the following vector sequence $$\cbk{\rmat{\tfrac{1}{m} \\ \vdots \\ \tfrac{1}{m}}}_{m \in \N}$$ we see that for any distinct $m, n$ it holds that $$\norm{v_m - v_n} = \sqrt{\rbk{\dfrac{1}{m} -\dfrac{1}{n}}^2 + \rbk{\dfrac{1}{m} -\dfrac{1}{n}}^2} = \sqrt 2 \abs{\dfrac{1}{m} -\dfrac{1}{n}}$$ Therefore, for any $\varepsilon > 0$ it suffices to take any $N > \dfrac{2 \sqrt 2}{\varepsilon}$ such that $$\forall m, n > N \quad \norm{v_m - v_n} < \varepsilon$$

We are finally ready to define Hilbert spaces.

\begin{frameddefn}{Hilbert space}
	A \tbf{Hilbert space} is a \tit{complete} scalar product vector space, i.e. it is a vector space

	\begin{itemize}
		\item equipped with a scalar product
		\item such that every Cauchy sequence converges strongly to an element in the space.
	\end{itemize}
\end{frameddefn}

For example, the space $\R^n$ is a Hilbert space. Indeed, since every finite vector space of size $n$ is isomporphic to $\R^n$, we can immediately derive the following proposition.

\begin{framedprop}{}
	Finite-dimensional vector spaces are always complete.
\end{framedprop}

\subsection{Linear operators}

Given a Hilbert space $\mathcal H$, we can define \tbf{operators} --- which are nothing but linear maps.

\begin{frameddefn}{Adjoint operator}
	Given a Hilbert space $\mathcal H$, and an operator $A$, the \tbf{adjoint} operator of $A$, denoted with $A^\dag$, is a linear map that satisfies the following property $$\forall u, v \in \mathcal H \quad \braket{u|A^\dag v} = \braket{Au|v}$$ We say that an operator $A$ is \tbf{self-adjoint}, or \tit{Hermitian}, if and only if $A = A^\dag$.
\end{frameddefn}

For instance, the following matrix $S = \rmat{1 & 0 \\ 0 & i}$ is a linear operator whose adjoint is $S^\dag = \rmat{1 & 0 \\ 0 & -i}$. In fact, we have that $$\braket{u|S^\dag v} = \rmat{\overline{u_1} & \overline{u_2}} \rmat{1 & 0 \\ 0 & -i} \rmat{v_1 \\ v_2} = \rmat{\overline{u_1} & \overline{u_2}} \rmat{v_1 \\ -iv_2} = \overline{u_1}v_1 - i\overline{u_2}v_2$$ and since $$Su = \rmat{1 & 0 \\ 0 & i}\rmat{u_1 \\ u_2} = \rmat{u_1 \\ iu_2} \implies \bra{Su} = \rmat{\overline{u_1} & \overline{i u_2}}$$ but because $\overline{iu_2} = \overline i \cdot \overline{u_2} = -i \overline{u_2}$ this implies that $$\braket{Su |v} = \rmat{\overline{u_1} & -i\overline{u_2}} \rmat{v_1 \\ v_2} = \overline{u_1}v_2 - i\overline{u_2}v_2$$

\begin{framedprop}[label={adj prop}]{}
	For any adjoint operators $A, B$ defined over some Hilbert space $\mathcal H$, it holds that

	\begin{enumerate}
		\item $(AB)^\dag = B^\dag A^\dag$
		\item for any scalar $z$ it holds that $(zA)^\dag = \overline z A^\dag$
		\item $(A^\dag)^\dag = A$
                \item $(A + B)^\dag = A^\dag + B^\dag$
	\end{enumerate}
\end{framedprop}

How do we evaluate the adjoint of a given operator?

\begin{framedprop}{}
    Given an operator $A$ defined over a scalar product vector space, it holds that $$A_{ij}^\dag = \overline{A_{ji}}$$
\end{framedprop}

\begin{framedprop}{}
	If an operator $A$ is self-adjoint, it holds that $$\braket{u|Av} = \braket{Au|v} = \overline{\braket{v|Au}}$$
\end{framedprop}

\begin{proof}
	TODO \todo{TODO}
\end{proof}

At the beginning of the previous chapter we said that all quantum gates are \tit{unitary transformations}, but we did now provide a definition of unitary. Now we are ready to introduce it, and start to grasp why we are discussing Hilbert spaces.

\begin{frameddefn}{Unitary operators}
	Given a Hilbert space $\mathcal H$, and an operator $U$, we say that $U$ is \tbf{unitary} if it holds that $$UU^\dag = U^\dag U = I$$
\end{frameddefn}

In other words, $U$ is unitary if and only if its adjoint operator is also its inverse. An interesting characterization of unitary transformations is the following property.

\begin{framedprop}{Unitary operators (alt. def.)}
	An operator $U$ defined over a Hilbert space $\mathcal H$ is unitary if and only if

	\begin{itemize}
		\item $U$ is surjective
		\item $\forall x, y \in \mathcal H \quad \braket{Ux|Uy} = \braket{x|y}$ or equivalently, if it holds that $$\forall x \in \mathcal H \quad \norm{Ux} = \norm x$$
	\end{itemize}
\end{framedprop}

\begin{proof}
    TODO \todo{TODO}
\end{proof}

In particular, we observe that the second property of this proposition is very interesting: the \tit{preservation of scalar product}, i.e. the property for which $$\forall x, y \in \mathcal H \quad \braket{Ux|Uy} = \braket{x|y}$$ means that the operator $U$ does not change the geometric relationships between vectors --- i.e. their lengths and angles remain the same.

\begin{framedprop}[label={unitary prod}]{}
    If $A$ and $B$ are two unitary operators, then $AB$ is a unitary operator.
\end{framedprop}

\begin{proof}
    Since $A$ and $B$ are unitary it holds that $$A ^\dag A = A A^ \dag = B ^ \dag B = B B^ \dag = I$$ Now, by \cref{adj prop} we have that $$(AB)^ \dag = B^\dag A^\dag$$ from which we conclude that $$(AB)^\dag(AB) = B^\dag A^\dag AB = B^\dag I B = B^\dag B = I$$
\end{proof}

\begin{frameddefn}{Normal operators}
	Given a Hilbert space $\mathcal H$, and an operator $A$, we say that $A$ is \tbf{normal} if it satisfies the following property $$A^\dag A = AA^\dag$$
\end{frameddefn}

Clearly, from their definition we immediately see that both self-adjoint and unitary operators are both normal.

\section{Spectral theory}

Since unitary operators are linear maps, we are interested in their eigenvectors and eigenvalues --- which are defined as usual. First, let us recall some preliminary definitions.

\begin{frameddefn}{Non-degenerate eigenvalue}
	Given a matrix $A$, and an eigenvalue $\lambda$ of $A$, we say that $\lambda$ is \tbf{non-degenerate} if the associated eigenspace has dimension 1 (or equivalently, if it has only 1 associated eigenvector).
\end{frameddefn}

\begin{frameddefn}{$d$-fold degenerate eigenvalue}
	Given a matrix $A$, and an eigenvalue $\lambda$ of $A$, we say that $\lambda$ is $d$-fold degenerate if there are $d$ linearly independent eigenvectors $u_1, \ldots, u_d$ associated to $\lambda$.
\end{frameddefn}

In Dirac notation, if $\lambda$ is non-degenerate, we refer to the only eigenvector associated to $\lambda$ as $\ket \lambda$, indeed it holds that $$A \ket \lambda = \lambda \ket \lambda$$

\begin{framedprop}{}
	Given a matrix $A$ defined over a Hilbert space $\mathcal H$, and an eigenvalue $\lambda$ associated to $A$, it holds that $$\bra \lambda A^\dag = \overline \lambda \bra \lambda$$
\end{framedprop}

\begin{proof}
	TODO \todo{TODO}
\end{proof}

The following theorem provides a characterization of the eigenvalues and eigenvectors of self-adjoint and unitary operators, which have suprisingly nice properties.

\begin{framedthm}{Spectral theorem}
	The following propositions hold:

	\begin{itemize}
		\item The eigenvalues of a self-adjoint operator are real values.
		\item The eigenvalues of a unitary operator are complex values of modulus 1.
		\item Eigenvectors of self-adjoint and unitary operators associated to different eigenvalues are orthogonal to each other.
	\end{itemize}
\end{framedthm}

Moreover, for finite-dimensional Hilbert spaces the following holds.

\begin{framedthm}{Spectral theorem for fin. Hilbert spaces}
    Given a finite-dimensional Hilbert space $\mathcal H$, and a normal operator $A$ defined over $\mathcal H$, the set of all eigenvectors of $A$ is an orthonormal basis for $\mathcal H$.
\end{framedthm}

We can rewrite this thorem as follows: if we denote with $u_{ij}$ the $j$-th eigenvector associated to the $i$-th eigenvalue of $A$, it holds that $$\forall v \in \mathcal H \quad v = \sum_{i = 1}^m{\sum_{j = 1}^{d_i}{\alpha_{ij} u_{ij}}}$$ where $d_i$ is the geometric multiplicity of the $i$-th eigenvalue of $A$. Indeed, we observe that $\dim \mathcal H = \sum_{i = 1}^m{d_i}$. Lastly, through the Dirac notation we can rewrite the formula as follows $$\forall v \in \mathcal H \quad \ket v = \sum_{i = 1}^m{\sum_{j = 1}^{d_i}{\braket{\lambda_{ij}|v} \ket{\lambda_{ij}}}}$$

\section{Projectors}

Next, we are going to discuss \tbf{projectors}, which are another very crucial pieces of quantum computation. We saw how scalar products are able to perform projection over desired direction, in fact we will use the Dirac notation to define precise operators for our purposes. But as always, first some preliminary definitions.

\begin{frameddefn}{Orthogonal space}
    Given a scalar product vector space $U$, and two linear subspaces $V, W \subset U$, we say that $V$ is orthogonal to $W$ if $$\forall v \in V, w \in W \quad \braket{v|w} = 0$$
\end{frameddefn}

Given a scalar product vector space $U$, and a linear subspace $V \subset U$, the \tbf{orthogonal complement} of $V$ is defined as follows: $$V^\bot := \{u \in U \mid \forall v \in v \quad \braket{u|v} = 0\}$$ In particular, we observe that if $U$ is finite-dimentional it holds that $V = U - V^\bot$ and that $(V^\bot)^\bot = V$.

\begin{frameddefn}{Topologically closed subspace}
    Given a Hilbert space $\mathcal H$, and a linear subspace $V \subset \mathcal H$, we say that $V$ is \tbf{topologically closed} if any sequence of vectors defined over $V$ converges in $V$.
\end{frameddefn}

Interestingly enough, given a topologically closed subspace $V \subset \mathcal H$ of some Hilbert space, we can write any vector $u \in V$ as the sum of two orthogonal vectors of $V$ and $V^\bot$, as follows. Let $\{f_1, \ldots, f_n\}$ be an orthonormal basis of $V$, and define the following vectors $$\forall u \in U \quad u_V := \sum_{i = 1}^n{\braket{f_i|v} f_i}$$ Then, if we call $$u_{V^\bot} := u - u_V$$, we see that
% \begin{equation*}
%     \begin{alignedat}{2}
%         \braket{u_V|u_{V^\bot}} &= \braket{u_V|u - u_V} & \\ 
%                                 &= \braket{u_V|u} - \braket{u_V|u_V} & \\ 
%                                 &= \braket{\sum_{i = 1}^n{\braket{f_i|u} f_i}|u} - \braket{u_V|u_V} & \\ 
%                                 &= \sum_{i = 1}^n{\braket{f_i|u} \braket{f_i|u}} - \braket{u_V|u_V} & \\ 
%                                 &= \sum_{i = 1}^n{\abs{\braket{f_i|u}}^2} - \braket{u_V|u_V} & \\ 
%                                 &= \sum_{i = 1}^n{\overline{\braket{f_i|u}} \braket{f_i|u}} & \quad (\mbox{since $\abs{z}^2 = z \cdot \overline z$}) \\ 
%                                 & = \sum_{i = 1}^n{\sum_{j = 1}^n{\overline{\braket{f_i|u}} \braket{f_j|u} \delta_{i j}}} & \quad (\mbox{since $\delta_{ij} = \braket{f_i|f_j}$})
%     \end{alignedat}
% \end{equation*}
TODO \todo{decommenta e finisci la formula} which indeed proves that $u_V$ and $u_{V^\bot}$ are orthogonal to each other.

With this observation, we can finally define the projector operators.

\begin{frameddefn}{Projector}
    Given a Hilbert space $\mathcal H$, and a closed subspace $V \subset \mathcal H$, the \tbf{projector} operator that projects any given vector $v \in \mathcal H$ onto $V$ is defined as follows: $$\funcmap{P_V}{\mathcal H}{V}{u}{u_V = \sum_{i = 1}^n{\braket{f_i|u} f_i}}$$ where $\{f_1, \ldots, f_n\}$ is an orthonormal basis of $V$.
\end{frameddefn}

In other words, the projector we have that $$P_V := \sum_{i = 1}^n{\ket{f_i} \bra{f_i}}$$ Clearly, by definition of $u_{V^\bot}$ it holds that $$\funcmap{P_{V^\bot}}{\mathcal H}{V^\bot}{u}{u_{V^\bot} := u - u_V}$$ Moreover, since $P_V$ performs a projection, we have that $$\forall u \in \mathcal H \quad u \in V \iff P_Vu = u$$ and that $$\forall u \in \mathcal H \quad u \in V^\bot \iff P_V u = 0$$ Additionally, for any projector $P_V$ it holds that $P_V^2 = P_V$, by idempotency, and $P_V^\dag = P_V$. TODO \todo{SCRIVERE DELLA NOTAZIONE DI DIRAC}

\begin{framedprop}{}
    Any projector operator only has 0 and 1 as possible eigenvalues.
\end{framedprop}

\begin{proof}
    Consider a projector operator $P_V$; by definition $v$ is an eigenvalue of $P_V$ associated to the eigenvalue $\lambda$ if it holds that $$P_Vv = \lambda v$$ Hence, we observe that $$P_V^2 v = P_V (P_V v) = P_V(\lambda v) = \lambda P_Vv = \lambda(\lambda v) = \lambda^2 v$$ and by idempotency of $P_V$ it holds that $$\lambda^2 v = P_V^2 = P_Vv = \lambda v$$ which implies that $$\lambda^2v - \lambda v = 0 \iff (\lambda^2 - \lambda)v = 0$$ Finally, since $v$ is an eigenvector it holds that $v \neq 0$, therefore it must be that the last equation is true only if $$\lambda^2 - \lambda = 0 \iff \lambda = 0 \lor \lambda = 1$$
\end{proof}

Given a Hilbert space $\mathcal H$, and two topologically closed subspaces $V, W \subset \mathcal H$, we say that $P_V$ and $P_W$ are \tbf{orthogonal} if it holds that $V \bot W$. Now, fix a vector $u \in \mathcal H$; by definition $P_Vu$ is a vector that lies inside $V$, therefore it holds that $$P_W(P_Vu) = 0$$ since $V \bot W$, and by the same reasoning applied on $W$ first we conclude that $$P_WP_V = P_VP_W = \mathbf 0$$ where $\mathbf 0$ is the \tbf{zero operator} --- indeed, it is a zero matrix.

As a final note, if $A$ is an linear operator, and $\lambda$ is an eigenvalue of $A$, we denote with $P_\lambda$ the projector that projects vectors onto the eigenspace associated to $\lambda$.

\begin{framedprop}[lambda={projector sum}]{}
    If $P$ and $Q$ are two orthogonal projectors, then $P + Q$ is still a projector.
\end{framedprop}

\begin{proof}
    TODO \todo{TODO}
\end{proof}

\section{Tensor product}

Finally, the last ingredient that we need to discuss is the \tbf{tensor product}

TODO \todo{TODO}

\section{Rules of quantum mechanics}

Now that we defined Hilbert spaces and their operators in great detail, we can finally present we needed this mathematical foundations in order to progress: quantum mechanics is developed over Hilbert spaces with \tit{countable} bases, and quantum computing works with finite-dimensional Hilbert spaces. In particular, there are four fundamental \tbf{postulates of quantum mechanics} which describe the \todo{what?}:

\begin{enumerate}
	\item \tbf{State postulate}: the state of a quantum system is completely described by a vector $\ket \psi$ in a Hilbert space $\mathcal H$ --- $\ket \psi$ is usually normalized, as we saw at the beginning of the previous chapter, and physical systems of different types live in different Hilbert spaces.
	\item \tbf{Measurement postulate}: every measurable (i.e. \tit{observable}) quantity corresponds to a self-adjoint operator on $\mathcal H$. In particular, given an observable $A$, and a state $v \in \mathcal H$, it holds that:
            \begin{itemize}
                \item the only possible results of measuring $A$ are one of its eigenvalues
                \item the probability of measuring eigenvalue $\lambda$ in state $v$ is given by $$\Pr[A = \lambda \mid v] = \braket{v|P_\lambda v}$$ where $P_\lambda$ is the linear map that projects $v$ onto the $\lambda$-eigenspace
            \end{itemize}
        \item \tbf{Time evolution postulate}: a closed system evolves through time according to the Schr√∂dinger equation $$i \hbar \dfrac{\diff}{\diff t} v(t) = Hv(t)$$ where the elements of this first-order linear differential equation are the following:

            \begin{itemize}
                \item $v(t)$ is the state vector at time $t$ (a vector in a Hilbert space)
                \item $H$ is the system \tit{Hamiltonian}, a self-adjoint operator that describes the total energy of the system
            \end{itemize}
        \item \tbf{Composite systems postulate}: the Hilbert space of a composite system is the tensor product of the Hilbert spaces of its subsystems. In other words, if system $A$ is defined over $\mathcal H_A$, and system $B$ is defined over $\mathcal H_B$, the total system lives in $$\mathcal H_{AB} = \mathcal H_A \otimes \mathcal H_B$$
\end{enumerate}

If we take a closer look at the second postulate, we can actually explain why we choose that particular scalar product to be the probability. Since by convention any quantum state is normalize, i.e. $\norm v = 1$, it holds that
\begin{equation*}
    \begin{split}
        1 & = \norm{v}^2 \\ 
          & = \braket{v|v} \\ 
          & = \abk{\sum_{i = 1}^m{P_{\lambda_iv}}\middle|\sum_{j = 1}^m{P_{\lambda_jv}}} \\ 
          & = \sum_{i = 1}^m{\sum_{j = 1}^m{\braket{P_{\lambda_i}v|P_{\lambda_j}v}}} \\ 
      \end{split}
\end{equation*}
Now, since each $P_{\lambda_i}$ is a projector, we know that when $i \neq j$ it holds that $P_{\lambda_i}P_{\lambda_j} = \mathbf 0$, therefore by self-adjointness of projectors we have that

\begin{itemize}
    \item if $i \neq j$ then $$\braket{P_{\lambda_i}v|P_{\lambda_j}v} =\braket{v|P_{\lambda_i}P_{\lambda_j}v} = \braket{v| \mathbf 0 v} = 0$$
    \item if $i = j$ then $$\braket{P_{\lambda_i}v|P_{\lambda_j}v} = \braket{P_{\lambda_i}v|P_{\lambda_i}v} = \norm{P_{\lambda_i}v}^2$$
\end{itemize}

Therefore, by adding only the non-zero terms we get that $$\sum_{i = 1}^m{\norm{P_{\lambda_i}v}^2} = 1$$ Hence, we define $$\Pr[A = \lambda_i \mid v] := \norm{P_{\lambda_i}v}^2$$ such that $$\Pr[A \mid v] = \sum_{i = 1}^m{\Pr[A = \lambda_i \mid v]} = \sum_{i = 1}^m{\norm{P_{\lambda_i}v}^2} = \norm{v}^2 = 1$$ which also means that our probabilities will add up to 1 automatically. Finally, we can rewrite this proability as follows (we will drop the index of the eigenvalue):
\begin{equation*}
    \begin{alignedat}{2}
        \Pr[A = \lambda \mid v] & = \braket{P_\lambda v | P_\lambda v} & \quad (\mbox{by def. of adjoint}) \\ 
                             & = \braket{v | P_\lambda^\dag P_\lambda v} & \quad (\mbox{by self-adjointness}) \\ 
                             & = \braket{v | P_\lambda^2 v} & \quad (\mbox{by idempotency}) \\ 
                             & = \braket{v | P_\lambda P_\lambda v} & \\ 
                             & = \braket{v | P_\lambda v} & \\ 
    \end{alignedat}
\end{equation*}

Another postulate that we need to discuss is the third one, regarding the Schr√∂dinger equation. In particular, the solution of the latter is $$v(t_1) = U(t_2, t_1)v(t_1)$$ where $U(t_2, t_1)$ is called \tbf{time-evaluation operator}, and it is defined as follows: $$U(t_2, t_1) = e^{-\tfrac{i}{\hbar}H(t_2 - t_1)}$$ (assuming $H$ does not depend on time). We recall that $H$ is a matrix, so we are raising $e$ to the power of a matrix, an operation that is defined by the power series of the exponential as follows: $$e^A = \sum_{n = 0}^\infty{\dfrac{A^n}{n!}}$$ What is interesting about this operator is that $U$ is \tbf{unitary}, and in order to show it is suffices to prove that $U^\dag = U^{-1}$. But how do we compute the adjoint of $U$? We observe that by the properties of the adjoint operation it holds that $$\rbk{e^A}^\dag = \rbk{\sum_{n = 0}^\infty{\dfrac{A^n}{n!}}}^\dag = \sum_{n = 0}^\infty{\dfrac{(A^n)^\dag}{n!}} = \sum_{n = 0}^\infty{\dfrac{(A^\dag)^n}{n!}} = e^{A^\dag}$$ which means that the adjoint of an exponential is the exponential of the adjoint. This suffices to prove that $$U^\dag = \rbk{e^{-\tfrac{i}{\hbar}H(t_2 - t_1)}}^\dag = e^{\rbk{-\tfrac{i}{\hbar}H(t_2 - t_1)}^\dag} = e^{\tfrac{i}{\hbar}H(t_2 - t_1)} = \rbk{e^{-\tfrac{i}{\hbar}H(t_2 - t_1)}}^{-1} = U^{-1}$$ This is a crucial characteristic for quantum mechanics: since $U$ is unitary, we know that it preserves the scalar product, therefore it also preserve \tbf{probabilities and norms}. This is why we say that evolution in quantum systems --- or \tit{quantum evolution}, for short --- is unitary.

\chapter{Quantum algorithms}

TODO \todo{non so di che parler√† il capitolo}

% \section{Peculiarities of quantum computation}

% \subsection{Reversible computation}

When we introduced quantum operators we underlined the fact that each quantum gate has to be a \tit{unitary} operator, and we now have the mathematical foundation to know that if a matrix is unitary, it is clearly also invertible --- indeed, its adjoint is its inverse. This directly implies a very important property of quantum computation: except for the measurement operation, every quantum computation operation is \tbf{reversible}.

Truth be precise, classical computation \tit{admits} reversible computation. In fact, we observe that we do have examples of reversible classical computaion that does not lose efficiency --- in terms of time. In 1963 \textcite{lecerf} proposed a reversible Turing machine, and in 1973 a landmark result by \textcite{bennett} proved that any standard Turing machine can be actually simulated by a reversible one --- his construction involves augmenting the Turing machine with an auxiliary \tit{history tape}, which can potentially lead to a large space overhead.

Consider the following bitwise operator $T$, that given three bits it works as follows: $$\funcmap{T}{\{0, 1\}^3}{\{0, 1\}^3}{(a, b, c)}{(a, b, c \oplus (a \land b))}$$ The corresponding classical gate of this bitwise operator is called \tbf{Toffoli gate}, and it has very special characteristics. First, observe how it computes: while $a$ and $b$ remains unchanged, $c$ is basically flipped if and only if both $a$ and $b$ are set to 1. In other words, both $a$ and $b$ act as \curlyquotes{control bits}over the \curlyquotes{target bit} $c$, indeed the Toffoli gate is sometimes called \tbf{Controlled Controlled NOT (CCNOT)}. As we did for the CNOT, this operator is clearly invertible since we are passing the bits $a$ and $b$ to the output too --- also, the truth table of the Toffoli gate easily shows that it is indeed invertible. Moreover, we observe that by associativity of the XOR it holds that $$(c \oplus (a \land b)) \oplus (a \land b) = c \oplus (a \land b) \oplus (a \land b) = c$$ which directly implies that $$T^2 = I \implies T = T^{-1}$$ However, above all the most important property of the Toffoli gate is that it is \tbf{universal}. In fact, even though gates like NAND and NOR are universal too, they are \tit{irreversible}. This implies that with the $T$ operator we can build any reversible Boolean function, and since any ordinary Boolean function can be embedded into a reversible one --- by adding extra bits to make it invertible --- any classical computation can be simulated using Toffoli gates only.

\section{Deutsch's algorithm}

Even though quantum computation provides reversibility \curlyquotes{for free}, we saw that classical computation can still achieve invertibility of computation. However, the next characteristic that we are going to describe has no classical analogue.

First, let's start with a problem seemingly unrelated to our discussion. Given a Boolean function $\func{f}{\{0, 1\}^n}{\{0, 1\}}$, we would like to embed $f$ inside a quantum computation. However, when $n \ge 3$ we are guaranteed that $f(x)$ is not reversible --- it cannot be injective. This is a problem, since in quantum coputing all gates must be reversible --- given that quantum evolution is unitary. Thus, how do we turn $f$ into a reversible computation?

We define a map $U_f$ defined as follows: $$\funcmap{U_f}{\{0, 1\}^{n + 1}}{\{0, 1\}^{n + 1}}{(x, y)}{(x, y \oplus f(x))}$$ First, we observe that $$(y \oplus f(x)) \oplus f(x) = y \oplus (f(x) \oplus f(x)) = y$$ which trivially proves that $U_f$ is reversible. Moreover, we can actually prove that when applied to qubits the corresponding quantum operator $$\funcmap{U_f}{\mathcal H}{\mathcal H}{\ket x \ket y}{\ket x \ket{y \oplus f(x)}}$$ is indeed unitary --- we observe that we are omitting the tensor product symbol in the function definition, as usual in the literature.

\begin{framedprop}{}
    Given a Boolean function $\func{f}{\{0, 1\}^n}{\{0, 1\}}$, the operator $U_f$ is unitary.
\end{framedprop}

\begin{proof}
    TODO \todo{TODO}
\end{proof}

This proves that the construction of $U_f$ is precisely the gate that allows us to embed $f$ into any quantum computation. Moreover, we observe that

\begin{itemize}
    \item $\ket y = \ket 0 \implies U_f \ket x \ket 0 = \ket x \ket{f(x)}$
    \item $\ket y = \ket 1 \implies U_f \ket x \ket 1 = \ket x \ket{\lnot f(x)}$
\end{itemize}

However, until now we only considered already collapsed qubits, but what if we consider a quantum input that is in a superposition? For instance, let $$\ket x = \dfrac{1}{\sqrt 2}(\ket 0 + \ket 1)$$ and assume that $\ket y = \ket 0$ for simplicity; this implies that
\begin{equation*}
    \begin{alignedat}{2}
        U_f \ket x \ket y & = U_f \dfrac{1}{\sqrt 2}(\ket 0 + \ket 1) \otimes \ket 0 & \\ 
                          & = U_f \dfrac{1}{\sqrt 2}(\ket{00} + \ket{10}) & \\ 
                          & = \dfrac{1}{\sqrt 2}(U_f \ket {00} + U_f \ket {10}) & \quad (\mbox{by linearity of $U_f$}) \\ 
                          & = \dfrac{1}{\sqrt 2}(\ket 0 \ket{f(0)} + \ket{1} \ket{f(1)}) & \\ 
    \end{alignedat}
\end{equation*}
But notice what just happened: both $f(0)$ and $f(1)$ have been computed \tbf{simultaneously}, in one gate application. This has no classical equivalent, we would have to evaluate $f(0)$ and $f(1)$ \tit{separately}. This phenomenon is called \tbf{quantum parallelism}, and it can be achieved only because:

\begin{itemize}
    \item qubits are in superpositions
    \item quantum gates are linear
\end{itemize}

However, we observe that the result of our calculations is \tit{still a superposition}. In fact, if we measure the output of $U_f \ket x \ket y$ we would still get either $\ket 0 \ket{f(0)}$ or $\ket 1 \ket {f(1)}$, both with 50\% probability. This is a problem: the fact that we can compute $f(0)$ and $f(1)$ at the same time seems promising, but can we retrieve their actual values?

Unfortunately, this is not possible. Indeed, quantum parallelism cannot help us with \tit{local} properties --- i.e. when we need all individual outputs --- it can only help when we need \tbf{global} properties. This limit derives from the fact that measurements prevent \curlyquotes{seeing} both outcomes, in fact if we were able to compute $f(0)$ and $f(1)$ simultaneously from this superposition we would be violating the laws of quantum mechanics themselves.

Then, how do we extract useful \tit{global} information from the superposition output? In 1985 \textcite{deutsch} defined a quantum algorithm which is able to compute $f(0) \oplus f(1)$, which clearly tells us if $f(0)$ equals $f(1)$ or not.

\begin{framedalgo}{Deutsch algorithm}
    Given a Boolean function $f$ and 2 qubits, the algorithm returns $\ket 0$ if $f$ if $f(0) = f(1)$, $\ket 1$ otherwise. \\
    \hrule

    \quad
    \begin{algorithmic}[1]
        \Function{Deutsch}{$f$, $q_0$, $q_1$}
            \State $q_1 = X(q_1)$
            \State $q_0, q_1 = (H \otimes H)(q_0, q_1)$
            \State $q_0, q_1 = U_f(q_0, q_1)$
            \State $q_0 = H(q_0)$
            \State \tbf{return} $\mbox{measure}(q_0)$
        \EndFunction
    \end{algorithmic}
\end{framedalgo}

\centeredimage[The quantum circuit for Deutsch's algorithm. The box colored in \tit{magenta} labeled with \texttt{U\_f} represents a \curlyquotes{black-box} for whatever computation $U_f$ represents (which directly depends on the chioce of $f$).]{0.9}{../assets/deutsch.png}

Proving that this quantum circuit is correct will be a little more involved than the quantum teleportation one. First, we need a lemma that will simplify our calculations.

\begin{framedlem}[label={U lemma}]{}
    For any Boolean function $f$ defined on $n$ bits, and $a \in \{0, 1\}^n$, it holds that $$U_f \ket a \otimes \dfrac{1}{\sqrt 2}(\ket 0 - \ket 1) = (-1)^{f(a)} \ket a \otimes \dfrac{1}{\sqrt 2}(\ket 0 - \ket 1)$$
\end{framedlem}

\begin{proof}
    First, by algebraic manipulation we see that
    \begin{equation*}
        \begin{split}
            U_f \ket a \otimes \dfrac{1}{\sqrt 2}(\ket 0 - \ket 1) & = U_f \dfrac{1}{\sqrt 2}(\ket{a0} - \ket{a1}) \\ 
                                                                   & = \dfrac{1}{\sqrt 2}(U_f \ket{a0} - \ket{a1}) \\ 
                                                                   & = \dfrac{1}{\sqrt 2}(\ket{a \ f(a)} - \ket{a \ \lnot f(a)}) \\ 
        \end{split}
    \end{equation*}
    and now, we observe that

    \begin{itemize}
        \item if $f(a) = 0$, then $$\dfrac{1}{\sqrt 2}(\ket{a0} - \ket{a1}) = (-1)^0 \ket{a} \otimes \dfrac{1}{\sqrt 2}(\ket 0 - \ket 1)$$
        \item if $f(a) = 1$, then $$\dfrac{1}{\sqrt 2}(\ket{a1} - \ket{a0}) = (-1)^1 \ket{a} \otimes \dfrac{1}{\sqrt 2}(\ket 0 - \ket 1)$$
    \end{itemize}
\end{proof}

We are now ready to prove the correctness of Deutsch's algorithm. To make things less cluttered, we will use the following standard notation: $$\ket + := \dfrac{1}{\sqrt 2}(\ket 0 + \ket 1) \quad \quad \ket - := \dfrac{1}{\sqrt 2}(\ket 0 - \ket 1)$$ In particular, we observe that $$H \ket 0 = \ket + \quad \quad H \ket 1 = \ket - $$ Moreover, we will omit the subscript of the corresponding qubit when the context is clear enough
\begin{equation*}
    \begin{alignedat}{2}
      & q_0 \otimes q_1 &  \\ 
        = & \ket 0 \otimes \ket 0 & \\ 
        \xrightarrow{X(q_1)} & \ket 0 \otimes \ket 1 & \\ 
        \xrightarrow{(H \otimes H)(q_0, q_1)} & \ket + \otimes \ket - &  \\ 
        = & \dfrac{1}{\sqrt 2}(\ket{00} - \ket{01} + \ket{10} - \ket{11}) & \\ 
        = & \dfrac{1}{\sqrt 2} \ket 0_0 \ket -_1  + \dfrac{1}{\sqrt 2} \ket 1_0 \ket -_1 & \\ 
        \xrightarrow{U_f(q_0, q_1)} & \dfrac{1}{\sqrt 2} (-1)^{f(0)} \ket 0_0 \ket -_1 + \dfrac{1}{\sqrt 2} (-1)^{f(1)} \ket 1_0 \ket -_1 & \quad (\mbox{by the lemma}) \\ 
        = & \dfrac{1}{\sqrt 2}\rbk{(-1)^{f(0)} \ket 0_0 + (-1)^{f(1)} \ket 1_0} \otimes \ket -_1 & \\ 
        \xrightarrow{H(q_0)} & \dfrac{1}{\sqrt 2}\rbk{(-1)^{f(0)} \ket +_0 + (-1)^{f(1)} \ket -_0} \otimes \sqrt 2 \ket -_1 & \\ 
        = & \dfrac{1}{2} \rbk{(-1)^{f(0)}(\ket 0 + \ket 1) + (-1)^{f(1)}(\ket 0 - \ket 1)} \otimes \sqrt 2 \ket -_1 & \\ 
        = & \dfrac{1}{2}\rbk{\rbk{(-1)^{f(0)} + (-1)^{f(1)}} \ket 0 + \rbk{(-1)^{f(0)} - (-1)^{f(1)}} \ket 1} \otimes \sqrt 2 \ket -_1 & \\ 
    \end{alignedat}
\end{equation*}
Now, since the final operation of the circuit involves measuring $q_0 = \alpha \ket 0 + \beta \ket 1$, the only two things that we care about are its probability amplitudes, namely $$\alpha = \dfrac{1}{2}\rbk{(-1)^{f(0)} + (-1)^{f(1)}}$$ $$\beta = \dfrac{1}{2}\rbk{(-1)^{f(0)} + (-1)^{f(1)}}$$ and we see that

\begin{itemize}
    \item if $f(0) = f(1)$, then $$(-1)^{f(0)} = (-1)^{f(1)} \implies \soe{l}{\alpha = \tfrac{1}{2}\rbk{2(-1)^{f(0)}} = (-1)^{f(0)} \\ \beta = 0}$$ which implies that $$q_0 = (-1)^{f(0)} \ket 0 + 0 \cdot \ket 1 = (-1)^{f(0)} \ket 0$$ and we can ignore the $(-1)^{f(0)}$ factor since its a global phase
    \item if $f(0) \neq f(1)$, then $$(-1)^{f(0)} = - (-1)^{f(1)} \implies \soe{l}{\alpha = 0 \\ \beta = \tfrac{1}{2}\rbk{2(-1)^{f(0)}} = (-1)^{f(0)}}$$ which implies that $$q_0 = 0 \cdot \ket 0 + (-1)^{f(0)} \ket 1 = (-1)^{f(0)} \ket 1$$ by the same reasoning as the other case
\end{itemize}

In the end, this proves that if $f(0) = f(1)$, $q_0$ will collapse to $\ket 0$, while if $f(0) \neq f(1)$ $q_1$ will colapse to $\ket 1$, proving that Deutsch's algorithm works correctly.

\section{Deutsch-Josza algorithm}

Even though Deutsch's algorithm is quite interesting and offers advantages that classical computation cannot achieve, still it seems like it wouldn't be very usefult in practice. In fact, usually we are interested in the \tit{values} of $f(0)$ and $f(1)$, and as we already mentioned quantum mechanics will not allow us to compute both the values at the same time --- meaning that even if we use Deutsch's algorithm to now whether $f(0)$ is equal to $f(1)$ or not, we would still need to compute at least one between $f(0)$ and $f(1)$ in order to know both values.

This is because, in reality, the algorithm that we are using is only solving a particular case of a more complex problem. In fact, a couple of years later \textcite{dj} realized that if we use $q_1 = \ket 1$ and $q_0 = \ket{0^n}$ (i.e. we use $n$ qubits set to $\ket 0$) this algorithm is actually able to tell \tbf{constant} and \tbf{balanced} functions apart.

\begin{frameddefn}{Constant function}
    A Boolean function $\func{f}{\{0, 1\}^n}{\{0,1\}}$ is said to be \tbf{constant} if $$\exists b \in \{0, 1\} \quad \forall x \in \{0, 1\}^n \quad f(x) = b$$
\end{frameddefn}

The definition of constant Boolean function has nothing special, and balanced functions are exactly what the name suggests, i.e. half of the inputs output 0 and the other half output 1, which can be succintly expressed as follows.

\begin{frameddefn}{Balanced function}
    A Boolean function $\func{f}{\{0, 1\}^n}{\{0,1\}}$ is said to be \tbf{balanced} if it holds that $$\sum_{x \in \{0, 1\}^n}{f(x)} = 2^{n - 1}$$
\end{frameddefn}

We observe that a Boolean function can be neither constant nor balanced, so this decision problem is actually a \tbf{promise problem}: given a Boolean function $f$ that is either constant or balanced --- note that it cannot be both --- decide if the function is constant or balanced. Indeed, we see that Deutsch's algorithm solved the same exact problem for $n = 2$: in fact, if $f(0) = f(1)$ it means that $f$ is constant, otherwise the latter is balanced.

Moreover, this problem actually shows the power of quantum parallelism more evidently: with a classical computation, to solve this decision problem we would need at most $$2^{n - 1} + 1 = O(2^n)$$ queries to $f$, instead our quantum computation still only requires \und{one} evaluation of $f$ to solve the problem.

\begin{framedalgo}{Deutsch-Josza algorithm}
    Given a Boolean function $f$ and $n + 1$ qubits, the algorithm returns $\ket{0^n}$ if $f$ is constant, $\ket 1$ otherwise. \\
    \hrule

    \quad
    \begin{algorithmic}[1]
        \Function{DeutschJosza}{$f$, $q_0$, $q_1$}
            \State $q_1 = X(q_1)$
            \State $q_0, q_1 = (H^{\otimes n} \otimes H)(q_0, q_1)$
            \State $q_0, q_1 = U_f(q_0, q_1)$
            \State $q_0 = H^{\otimes n}(q_0)$
            \State \tbf{return} $\mbox{measure}(q_0)$
        \EndFunction
    \end{algorithmic}
\end{framedalgo}

Note that in this algorithm $q_0$ are actually $n$ qubits. Before proving the correctness of this general version of the algorithm, let us first take a look at the quantum circuit that defines it.

TODO \todo{drawing}

For our discussion we will call $\B = \{0, 1\}$.

\claim[Claim 1]{
    $\forall a \in \B \quad H \ket a = \tfrac{1}{\sqrt 2} \sum_{b \in \B}{(-1)^{a \cdot b} \ket b}$.
}{
    We observe that $$H \ket 0 = \ket + = \dfrac{1}{\sqrt 2}(\ket 0 + \ket 1) = \dfrac{1}{\sqrt 2} \sum_{b \in \B}{(-1)^{0 \cdot b} \ket b}$$ and analogously $$H \ket 1 = \ket - = \dfrac{1}{\sqrt 2}(\ket 0 - \ket 1) = \dfrac{1}{\sqrt 2} \sum_{b \in \B}{(-1)^{1 \cdot b} \ket b}$$
}

In the following claim, we will denote with the $\cdot$ symbol the \curlyquotes{canonical} scalar product, i.e. $$\forall x, y \in \B^n \quad x \cdot y := \sum_{i = 1}^n{x_i y_i}$$

\claim[Claim 2]{
    $\forall x \in \B^n \quad H^{\otimes n}\ket x = \tfrac{1}{\sqrt 2 ^n} \sum_{a \in \B^n}{(-1)^{x \cdot a} \ket a}$
}{
    By the previous claim, we have that
    \begin{equation*}
        \begin{alignedat}{2}
            H^{\otimes n} \ket x & = \bigotimes_{i = 1}^n{H \ket{x_i}} & \\ 
                                 & = \bigotimes_{i = 1}^n{\rbk{\dfrac{1}{\sqrt 2} \sum_{b \in \B}{(-1)^{x_ib} \ket b}} \ket{x_i} }  & \quad (\mbox{by Claim 1}) & \\ 
                                 & = \dfrac{1}{\sqrt 2^n} \bigotimes_{i = 1}^n{\rbk{\ket 0 + (-1)^{x_i} \ket 1}} & \\ 
                                 & = \dfrac{1}{\sqrt 2^n} \sum_{a \in \B^n}{(-1)^{x \cdot a} \ket a } & \\ 
        \end{alignedat}
    \end{equation*}
}

Finally, we are ready to prove the correctness of the algorithm.

\begin{equation*}
    \begin{alignedat}{2}
        & q_0 \otimes q_1 & \\ 
        = & \ket{0^n} \otimes \ket 0 & \\ 
        \xrightarrow{X(q_1)} & \ket{0^n} \otimes \ket 1 & \\ 
        \xrightarrow{H^{\otimes n}(q_0, q_1)} & H^{\otimes n} \ket{0^n} \otimes H \ket 1 & \\ 
        = & \dfrac{1}{\sqrt 2^n} \sum_{a \in \B^n}{(-1)^{0^n \cdot a} \ket a} \otimes \ket - & \quad (\mbox{by Claim 2}) \\ 
        = & \dfrac{1}{\sqrt 2} \sum_{a \in \B^n}{\ket a} \otimes \ket -  & \\ 
        = & \dfrac{1}{\sqrt 2^n } \sum_{a \in \B^n}{(\ket a \otimes \ket - )} & \\ 
        \xrightarrow{U_f(q_0, q_1)} & \dfrac{1}{\sqrt 2} \sum_{a \in \B^n}{\rbk{(-1)^{f(a)} \ket a \otimes \ket - }} & \quad (\mbox{by \cref{U lemma}}) \\ 
        = & \dfrac{1}{\sqrt 2 ^n} \sum_{a \in \B^n}{(-1)^{f(a)} \ket a} \otimes \ket - & \\ 
        \xrightarrow{H^{\otimes n}(q_0)} & H^{\otimes n} \rbk{\dfrac{1}{\sqrt 2 ^n} \sum_{a \in \B^n}{(-1)^{f(a)} \ket a }} \otimes \ket - & \\ 
        = & \dfrac{1}{\sqrt 2 ^n} \sum_{a \in \B^n}{\rbk{(-1)^{f(a)} H^{\otimes n} \ket a }} \otimes \ket - & \\ 
        = & \dfrac{1}{\sqrt 2 ^n} \sum_{a \in \B^n}{(-1)^{f(a)} \rbk{\dfrac{1}{\sqrt 2^n} \sum_{b \in \B^n} {(-1)^{a \cdot b} \ket b}}} \otimes \ket - & \quad (\mbox{by Claim 2}) \\ 
        = & \dfrac{1}{2^n} \sum_{a \in \B^n}{\sum_{b \in \B^n}{(-1)^{f(a) + a \cdot b}} \ket b } \otimes \ket - & \\ 
        = & \dfrac{1}{2^n} \sum_{a \in \B^n}{\sum_{b \in \B^n}{(-1)^{f(a) + a \cdot b}} \ket b } \otimes \ket - & \\ 
        = & \sum_{b \in \B^n}{\rbk{\dfrac{1}{2^n}\sum_{a \in \B^n}{(-1)^{f(a) + a \cdot b}}} \ket b_0} \otimes \ket -_1 & \\
    \end{alignedat}
\end{equation*}

Now note that this state describes the superposition of the system, but the next step of the algorithm will only measure $q_0$, therefore we can ignore $\ket -_1$ and just focus on the amplitudes of $q_0$. Then, by calling $$\forall b \in \B^n \quad \alpha_b := \dfrac{1}{2^n} \sum_{a \in \B^n}{(-1)^{f(a) + a \cdot b}}$$ we can rewrite $q_0$ as follows $$q_0 = \sum_{b \in \B^n}{\alpha_b \ket b}$$ Finally, since we want to determine the probability that $q_0$ collapses into the state $\ket{0^n}$ specifically, we can easily evaluate the associated amplitude of the latter, i.e. $$\alpha_{0^n} = \dfrac{1}{2^n}\sum_{a \in \B^n}{(-1)^{f(a)+ a \cdot 0^n}} = \dfrac{1}{2^n} \sum_{a \in \B^n}{(-1)^{f(a)}}$$ From this, we can easily conclude that:

\begin{itemize}
    \item if $f$ is constant, then $$\alpha_{0^n} = \dfrac{1}{2^n} \sum_{a \in \B^n}{(-1)^{f(a)}} = \dfrac{1}{2^n} \cdot 2^n \cdot (-1)^{b} = (-1)^b$$ where $b \in \B$, meaning that it is guaranteed that $q_0$ will collapse to $0^n$
    \item if $f$ is balanced, then $$\alpha_{0^n} = \dfrac{1}{2^n} \sum_{a \in \B}{(-1)^{f(a)}} = \dfrac{1}{2^n} \cdot 0 = 0$$ meaning that it is guaranteed that $q_0$ will \tit{not} collapse to $0^n$
\end{itemize}

\section{Grover's algorithm}

Even though Deutsch-Josza algorithm is able to solve the decision problem we described through \tit{one} single evaluation of $f$, it is fairly apparent that the problem their algorithm solves is quite artificial. However the next algorithm that we are going to discuss solve a problem that is definitely more useful.

In 1997, \textcite{grover} published a landmark paper called \curlyquotes{Quantum Mechanics Helps in Searching for a Needle in a Haystack}, and the name already suggests the problem his work tried to solve: the search problem. The setting is the following: we are given an array of $N$ elements --- we can assume that $N$ is always a power of 2 for some $n$, i.e. $N= 2^n$ --- that contains $M$ \curlyquotes{solution} elements. However, we do not know their positions, and the problem asks to find the index of any solution element.

More formally, given a Boolean function $$\func{f}{\{0, \ldots, N - 1\}}{\B}{x}{\soe{ll}{1 & A[x] \in S \\ 0 & \mbox{otherwise}}}$$ where $A$ is our array, and $S$ is the set of solution elements, the problem asks to return an $x$ such that $f(x) = 1$, i.e. such that $A[x]$ is a solution.

With a classical computation, it is easy to see that we need $O \rbk{\dfrac{N}{M}}$ accesses to $A$ to solve our problem, however we will see that the algorithm Grover developed is able to return a \curlyquotes{solution index} in $O\rbk{\sqrt{\dfrac{M}{N}}}$ with \tit{high probability}, i.e. Grover's algorithm provide a \tbf{quadratic} speedup compared to any classical algorithm --- however, the algorithm is probabilistic.

Before explaining the details of the algorithm, we need to defines some new operators that will be used in Grover's algorithm:

\begin{itemize}
    \item given a qubit $\ket \psi$, we will write its superposition of states as follows $$\ket \psi = \sum_{b \in \B^n}{\alpha_b \ket b}$$ where $\sum_{b \in \B^n}{\abs{\alpha_b}} = 1$
    \item from the above definition, we define the \tbf{average amplitude} of a qubit $\ket \psi$ as follows: $$\abk{\alpha}_\psi := \dfrac{1}{N}\sum_{b \in \B^n}{\alpha_b}$$
    \item we define an operator $O_f$ (where $f$ is the indicator function of the array defined before) that computes as follows: $$\forall b \in \B^n \quad O_f \ket b = (-1)^{f(x)} \ket b$$
    \item we define a new operator $W$ which computes the \tbf{inverse about the mean}: $$\forall b \in \B^n \quad W \ket b := (2 \abk{\alpha}_\psi - \alpha_b)\ket b$$ 
    \item finally, we will define an operator $G$ that will simply compose the last two operators we described $$G = W \cdot O_f$$
\end{itemize}

\claim[Claim 1]{
    Given a qubit $\ket \psi$, it holds that $W = P_\psi - P_{\psi^\bot}$ where $P_\psi$ is a projector on $\psi$'s space and $P_{\psi^\bot} \bot P_\psi$. Moreover, $W$ is unitary.
}{
    % By definition of the Dirac notation, we have that $P_\psi = \ket \psi \bra \psi$, 
    TODO \todo{capire la cosa psi normalizzato}
}

\claim[Claim 2]{
    The operator $G$ is unitary.
}{
    By \cref{unitary prod} we know that proving that $W$ and $O_f$ are unitary is sufficient, but since $W$ is unitary by Claim 1, we only need to show that $O_f$ is un itary as well. \todo{da finire}
}

\printbibliography % UNCOMMENT FOR BIBLIOGRAPHY

\end{document}
